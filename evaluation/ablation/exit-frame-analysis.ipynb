{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d127e40-f2ac-4232-bc33-280e930f1908",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8677230-ce92-420c-8b03-44769c7b4e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "output_dir = \"/data/apperception-data/exit-output/run\"\n",
    "\n",
    "performance_dir = os.path.join(output_dir, \"performance--q2-de_1\")\n",
    "noop_performance_dir = os.path.join(output_dir, \"performance--q2-noopt_1\")\n",
    "detection_dir = os.path.join(output_dir, \"detection--q2-de_1\")\n",
    "sort_dir = os.path.join(output_dir, \"sort--q2-de_1\")\n",
    "noop_sort_dir = os.path.join(output_dir, \"sort--q2-noopt_1\")\n",
    "\n",
    "\n",
    "def filter_cars(detections):\n",
    "    return [d for d in detections if d[-1] == 2.0]\n",
    "\n",
    "\n",
    "def extract_pairs(sort_results):\n",
    "    pairs = []\n",
    "    for detection in sort_results.values():\n",
    "        if detection:  # make sure detection is not empty\n",
    "            pairs.append((detection['object_id'], tuple(detection['detection_id'])))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def calculate_matches(current_sort_results, next_sort_results, current_noop_results, next_noop_results):\n",
    "    # Convert the results into lists of (object_id, detection_id) tuples\n",
    "    current_sort_pairs = extract_pairs(current_sort_results)\n",
    "    next_sort_pairs = extract_pairs(next_sort_results)\n",
    "    current_noop_pairs = extract_pairs(current_noop_results)\n",
    "    next_noop_pairs = extract_pairs(next_noop_results)\n",
    "\n",
    "    # Create dictionaries to map detection_ids to object_ids for current and next frames\n",
    "    current_sort_dict = {det_id: obj_id for obj_id, det_id in current_sort_pairs}\n",
    "    next_sort_dict = {det_id: obj_id for obj_id, det_id in next_sort_pairs}\n",
    "    current_noop_dict = {det_id: obj_id for obj_id, det_id in current_noop_pairs}\n",
    "    next_noop_dict = {det_id: obj_id for obj_id, det_id in next_noop_pairs}\n",
    "    TP = FP = FN = 0  # Initialize counts\n",
    "\n",
    "    # Calculate matches\n",
    "    for current_det_id, current_obj_id in current_sort_dict.items():\n",
    "        # Check if current detection id is in both current frame sort and noop\n",
    "        if current_det_id in current_noop_dict:\n",
    "            # Check if the next detection id for current detection id is the same in sort and noop\n",
    "            for next_det_id, next_obj_id in next_sort_dict.items():\n",
    "                if next_obj_id == current_obj_id:\n",
    "                    if next_det_id in next_noop_dict:\n",
    "                        if next_noop_dict[next_det_id] == current_noop_dict[current_det_id]:\n",
    "                            TP += 1  # True positive: detection id is correctly tracked from current to next\n",
    "                        else:\n",
    "                            FN += 1\n",
    "        else:\n",
    "            FP += 1  # False positive: detection id is tracked in sort but not in noop\n",
    "\n",
    "    # As before, TN is not calculated as it's not defined in this context\n",
    "    return TP, FP, FN\n",
    "\n",
    "\n",
    "performance_files = sorted(os.listdir(performance_dir))\n",
    "noop_performance_files = sorted(os.listdir(noop_performance_dir))\n",
    "sort_files = sorted(os.listdir(sort_dir))\n",
    "noop_sort_files = sorted(os.listdir(noop_sort_dir))\n",
    "# detection_files = sorted(os.listdir(detection_dir))\n",
    "\n",
    "skip_map = defaultdict(lambda: {\n",
    "    'count': 0,\n",
    "    'f1': [],\n",
    "    '_f1': [],\n",
    "    'tp': 0,\n",
    "    'fp': 0,\n",
    "    'fn': 0,\n",
    "    'de_strongsort_time': [],\n",
    "    'total_strongsort_time': []\n",
    "})\n",
    "\n",
    "\n",
    "def calculate_f1(TP, FP, FN):\n",
    "    # calculate f1 score for the skip_map\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    return f1\n",
    "\n",
    "\n",
    "for i in range(len(performance_files)):\n",
    "    with open(os.path.join(performance_dir, performance_files[i])) as f:\n",
    "        performance = json.load(f)\n",
    "    with open(os.path.join(noop_performance_dir, noop_performance_files[i])) as f:\n",
    "        noop_performance = json.load(f)\n",
    "    with open(os.path.join(sort_dir, sort_files[i])) as f:\n",
    "        sort_result = json.load(f)\n",
    "    with open(os.path.join(noop_sort_dir, noop_sort_files[i])) as f:\n",
    "        noop_sort_result = json.load(f)\n",
    "    # with open(os.path.join(detection_dir, detection_files[i])) as f:\n",
    "    #     all_detections = json.load(f)\n",
    "\n",
    "    detection_estimation_benchmark = performance[5][\"benchmark\"]\n",
    "    assert performance[6]['stage'] == 'Tracking2D.StrongSORT'\n",
    "    ss_de_benchmark = [p for p in performance if 'addition' in p and p['addition'] and p['stage'] == 'Tracking2D.StrongSORT'][0][\"benchmark\"]\n",
    "    strong_sort_benchmark = noop_performance[5][\"benchmark\"]\n",
    "    # import code; code.interact(local=dict(globals(), **locals()))\n",
    "    skip_track = detection_estimation_benchmark.get(\"skip_track\", [])\n",
    "\n",
    "    for track in skip_track:\n",
    "        current_f, next_f, process_time = track\n",
    "        skip_map[next_f-current_f-1][\"count\"] += 1\n",
    "        # print('frame_process_time' in ss_de_benchmark)\n",
    "        # print(ss_de_benchmark)\n",
    "        skip_map[next_f-current_f-1][\"de_strongsort_time\"].append(process_time + sum(ss_de_benchmark[\"frame_process_time\"][current_f:next_f]))\n",
    "        # Assuming sort_result and noop_sort_result are your pipeline results\n",
    "        TP, FP, FN = calculate_matches(sort_result[current_f],\n",
    "                                       sort_result[next_f],\n",
    "                                       noop_sort_result[current_f],\n",
    "                                       noop_sort_result[next_f])\n",
    "        skip_map[next_f-current_f-1][\"tp\"] += TP\n",
    "        skip_map[next_f-current_f-1][\"fp\"] += FP\n",
    "        skip_map[next_f-current_f-1][\"fn\"] += FN\n",
    "        skip_map[next_f-current_f-1][\"f1\"].append(calculate_f1(TP, FP, FN))\n",
    "\n",
    "        overskip_counted = False\n",
    "        # for f in range(current_f, next_f):\n",
    "        skip_map[next_f-current_f-1][\"total_strongsort_time\"].append(sum(strong_sort_benchmark[\"frame_process_time\"][current_f:next_f]))\n",
    "\n",
    "    # for k in skip_map.values():\n",
    "    #     k['de_strongsort_time'] /= k['count']\n",
    "    #     k['total_strongsort_time'] /= k['count']\n",
    "\n",
    "skip_map = dict(skip_map)\n",
    "for skip in skip_map:\n",
    "    skip_map[skip][\"_f1\"] = calculate_f1(skip_map[skip][\"tp\"], skip_map[skip][\"fp\"], skip_map[skip][\"fn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732580bc-12cf-4b0a-8a4b-4f7112278937",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = 0\n",
    "total_frame_skipped = 0\n",
    "for skipping_distance in skip_map:\n",
    "    total_frame_skipped += skipping_distance * skip_map[skipping_distance][\"count\"]\n",
    "    total_count += skip_map[skipping_distance][\"count\"]\n",
    "print(total_frame_skipped)\n",
    "print(total_count)\n",
    "print(total_frame_skipped/240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d582a2-9a70-4adf-aba3-e8cea54bb124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming skip_map is the dictionary you have after running the above code\n",
    "# Prepare the data for plotting\n",
    "x_values = []\n",
    "y_values = []\n",
    "for x, s in skip_map.items():\n",
    "    if x == 0:\n",
    "        continue\n",
    "    data_points = []\n",
    "    for t, d in zip(s['total_strongsort_time'], s['de_strongsort_time']):\n",
    "        data_points.append(t * 100 / d)\n",
    "    x_values.append(x)\n",
    "    y_values.append(np.average(data_points))\n",
    "# x_values = sorted(skip_map.keys())[1:]  # Sorting the keys to ensure the plot is ordered\n",
    "# y_values = [skip_map[k]['total_strongsort_time'] - skip_map[k]['de_strongsort_time'] for k in x_values]\n",
    "coef = np.polyfit(x_values, y_values, deg=1)\n",
    "poly1d_fn = np.poly1d(coef)\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 5))  # You can adjust the figure size as needed\n",
    "plt.scatter(x_values, y_values, color='steelblue', alpha=0.5)\n",
    "plt.plot(x_values, poly1d_fn(x_values), '--r')  # Create a bar plot\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Performance Enhancement: Exit Frame Sampler vs. Strongsort Runtime in Percentage')\n",
    "plt.xlabel('Skip Distance (frames)')\n",
    "plt.ylabel('Runtime Improvement (percent)')\n",
    "\n",
    "# Show grid lines for better readability\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a78cfe-69d3-4151-b6c2-32c311df7c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming skip_map is the dictionary you have after running the above code\n",
    "# Prepare the data for plotting\n",
    "x_values = []\n",
    "y_values = []\n",
    "for x, s in skip_map.items():\n",
    "    if x == 0 or x > 30:\n",
    "        continue\n",
    "    data_points = []\n",
    "    for t, d in zip(s['total_strongsort_time'], s['de_strongsort_time']):\n",
    "        data_points.append(d / t)\n",
    "    x_values.append(x)\n",
    "    y_values.append(100 * np.average(data_points))\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(3.5, 3.5))  # You can adjust the figure size as needed\n",
    "plt.scatter(x_values, y_values, color='steelblue', alpha=0.5)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Comparing StrongSORT with and without Exit Frame Sampler')\n",
    "plt.xlabel('Skip Distance (frames)')\n",
    "plt.ylabel('Average Runtime w.r.t. Baseline (%)')\n",
    "\n",
    "# Show grid lines for better readability\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b3a69b-8f7f-44e4-a7e2-bee983d6144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming skip_map is the dictionary you have after running the above code\n",
    "# Prepare the data for plotting\n",
    "x_values = []\n",
    "y_values = []\n",
    "for x, s in skip_map.items():\n",
    "    if x == 0 or x > 30:\n",
    "        continue\n",
    "    data_points = []\n",
    "    for t, d in zip(s['total_strongsort_time'], s['de_strongsort_time']):\n",
    "        data_points.append(t / d)\n",
    "    x_values.append(x)\n",
    "    y_values.append(100 / np.average(data_points))\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(5, 5))  # You can adjust the figure size as needed\n",
    "plt.scatter(x_values, y_values, color='steelblue', alpha=0.5)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Performance Enhancement: Exit Frame Sampler vs. Strongsort Runtime in Percentage')\n",
    "plt.xlabel('Skip Distance (frames)')\n",
    "plt.ylabel('Runtime Comparison (percent)')\n",
    "\n",
    "# Show grid lines for better readability\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf59fd7-cdba-4833-9861-b43330c276c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_values = sorted(skip_map.keys())[1:]  # Sorting the keys to ensure the plot is ordered\n",
    "# y_values = [sum(skip_map[k]['f1']) / len(skip_map[k]['f1']) for k in x_values]\n",
    "\n",
    "x_values = []\n",
    "y_values = []\n",
    "for x, s in skip_map.items():\n",
    "    for f1 in s['f1']:\n",
    "        x_values.append(x)\n",
    "        y_values.append(f1)\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 5))  # You can adjust the figure size as needed\n",
    "plt.scatter(x_values, y_values, color='steelblue', alpha=0.1)  # Create a bar plot\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('F1 Score')\n",
    "plt.xlabel('Skip Distance (frames)')\n",
    "plt.ylabel('F1 Score')\n",
    "\n",
    "# Show grid lines for better readability\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e6e895-c873-4318-86be-b5216bfd2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = sorted(skip_map.keys())[1:]  # Sorting the keys to ensure the plot is ordered\n",
    "y_values = [skip_map[k]['_f1'] for k in x_values]\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 5))  # You can adjust the figure size as needed\n",
    "plt.scatter(x_values, y_values, color='steelblue')  # Create a bar plot\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Comparative Analysis: F1 Scores of the Exit Frame Sampler')\n",
    "plt.xlabel('Skip Distance (frames)')\n",
    "plt.ylabel('F1 Score')\n",
    "\n",
    "# Show grid lines for better readability\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b39c204-24e1-41fa-a46a-7c4d8a046337",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = sorted(sk for sk in skip_map.keys() if sk <= 30)[1:]  # Sorting the keys to ensure the plot is ordered\n",
    "y_values = [skip_map[k]['_f1'] for k in x_values]\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(5, 5))  # You can adjust the figure size as needed\n",
    "plt.scatter(x_values, y_values, color='steelblue')  # Create a bar plot\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Comparative Analysis: F1 Scores of the Exit Frame Sampler')\n",
    "plt.xlabel('Skip Distance (frames)')\n",
    "plt.ylabel('F1 Score')\n",
    "\n",
    "# Show grid lines for better readability\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5ae3a-74d0-4700-b3dc-fe001497abfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = sorted(skip_map.keys())[1:]  # Sorting the keys to ensure the plot is ordered\n",
    "y_values = [skip_map[k]['_f1'] for k in x_values]\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 5))  # You can adjust the figure size as needed\n",
    "plt.bar(x_values, y_values, color='steelblue')  # Create a bar plot\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('F1 Score')\n",
    "plt.xlabel('Skip Distance (frames)')\n",
    "plt.ylabel('F1 Score')\n",
    "\n",
    "# Show grid lines for better readability\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59070d9-99fd-4af7-8a3c-d542ae41a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = []\n",
    "y_values = []\n",
    "for x, s in skip_map.items():\n",
    "    for f1 in s['f1']:\n",
    "        x_values.append(x)\n",
    "        y_values.append(f1)\n",
    "# data = np.zeros((60, 100), dtype=int)\n",
    "# for x, y in zip(x_values, y_values):\n",
    "#     data[x, int(y*100)] += 1\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# Plotting the data\n",
    "fig, ax = plt.subplots()\n",
    "# plt.figure(figsize=(10, 5))  # You can adjust the figure size as needed\n",
    "h = ax.hist2d(x_values, y_values, bins=(10, 10), norm=LogNorm())  # Create a bar plot\n",
    "fig.colorbar(h[3], ax=ax)\n",
    "\n",
    "# Add titles and labels\n",
    "ax.set_title('F1 Score')\n",
    "ax.set_xlabel('Skip Distance (frames)')\n",
    "ax.set_ylabel('F1 Score')\n",
    "\n",
    "# Show grid lines for better readability\n",
    "# ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc802755-59fb-444d-b457-f9c2250bfa0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ffba13-559c-410f-800a-2a38ba530446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd375d77-fae5-45fb-80c9-513eeb8b4eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3fe8c7-0fad-49f7-9b8c-22cb7c085c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcee0da6-58f6-4106-b4bb-18e3da50fa6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2001ff17-ada7-46b8-8d94-b65041e83187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_runtime(ax):\n",
    "    # Assuming skip_map is the dictionary you have after running the above code\n",
    "    # Prepare the data for plotting\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "    c_values = []\n",
    "    for x, s in skip_map.items():\n",
    "        if x == 0 or x > 30:\n",
    "            continue\n",
    "        data_points = []\n",
    "        for t, d in zip(s['total_strongsort_time'], s['de_strongsort_time']):\n",
    "            data_points.append(d / t)\n",
    "        x_values.append(x)\n",
    "        y_values.append(100 * np.average(data_points))\n",
    "        c_values.append(len(data_points))\n",
    "\n",
    "    ax.scatter(x_values, y_values, s=c_values, c=c_values)\n",
    "\n",
    "    # Add labels\n",
    "    ax.set_xlabel('Skip Distance (frames)')\n",
    "    ax.set_ylabel('Average Runtime w.r.t. Baseline (%)')\n",
    "\n",
    "    # Show grid lines for better readability\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "def plot_f1(ax):\n",
    "    x_values = sorted(sk for sk in skip_map.keys() if sk <= 30)[1:]  # Sorting the keys to ensure the plot is ordered\n",
    "    y_values = [skip_map[k]['_f1'] for k in x_values]\n",
    "\n",
    "    # Plotting the data\n",
    "    ax.scatter(x_values, y_values, color='steelblue')  # Create a bar plot\n",
    "\n",
    "    # Add titles and labels\n",
    "    ax.set_xlabel('Skip Distance (frames)')\n",
    "    ax.set_ylabel('Average F1 Score w.r.t. Baseline')\n",
    "\n",
    "    # Show grid lines for better readability\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 3.5))\n",
    "fig.suptitle('Comparing StrongSORT with and without Exit Frame Sampler')\n",
    "fig.tight_layout()\n",
    "\n",
    "plot_runtime(ax1)\n",
    "plot_f1(ax2)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1000546b-5b82-48e5-9524-d1814d7ab8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406b7142-fbcb-4779-be67-a5e0a7142e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "distance = 'Skip Distance (Frames)'\n",
    "runtime = 'Average Runtime Proportion'\n",
    "f1 = 'F1 Score'\n",
    "count = 'Number of skipping instance'\n",
    "for x, s in skip_map.items():\n",
    "    if x == 0 or x > 30:\n",
    "        continue\n",
    "    runtimes = []\n",
    "    for t, d in zip(s['total_strongsort_time'], s['de_strongsort_time']):\n",
    "        runtimes.append(d / t)\n",
    "\n",
    "    values.append({\n",
    "        distance: x,\n",
    "        runtime: np.average(runtimes),\n",
    "        # f1: np.average(s['f1']),\n",
    "        f1: s['_f1'],\n",
    "        count: len(runtimes),\n",
    "    })\n",
    "\n",
    "alt.Chart(pd.DataFrame.from_records(values)).mark_circle().encode(\n",
    "    x=alt.X(distance, type='quantitative'),\n",
    "    y=alt.Y(alt.repeat('column'), type='quantitative'),\n",
    "    # size=alt.Size(count, scale=alt.Scale(rangeMax=600)),\n",
    "    size=alt.SizeValue(60),\n",
    "    # color=alt.Color(count, scale=alt.Scale(scheme='viridis')),\n",
    "    color=alt.Color(\n",
    "        count,\n",
    "        scale=alt.Scale(scheme='viridis'),\n",
    "        # sort='descending',\n",
    "        legend=alt.Legend(\n",
    "            # values=[200, 400, 600, 746],\n",
    "            title=['Number of', 'skipping', 'instances'],\n",
    "            tickCount=6,\n",
    "            gradientLength=80,\n",
    "        ),\n",
    "    ),\n",
    "    stroke=alt.StrokeValue('black'),\n",
    "    strokeWidth=alt.StrokeWidthValue(1),\n",
    "    # strokeOpacity=alt.OpacityValue(1),\n",
    "    tooltip=[count]\n",
    ").properties(\n",
    "    width=150,\n",
    "    height=125,\n",
    ").repeat(\n",
    "    column=[runtime, f1]\n",
    ").properties(\n",
    "    title='Comparing StrongSORT with vs. without Exit Frame Sampler',\n",
    "    padding=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f928dc-b408-4024-9af9-dfe1031bc2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
