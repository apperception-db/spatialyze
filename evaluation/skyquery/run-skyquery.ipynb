{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "569e4726-2856-4e5f-a220-e3bef1c110e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec  1 22:19:34 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   70C    P8    13W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import traceback\n",
    "import shutil\n",
    "import socket\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "from os import environ\n",
    "from typing import NamedTuple\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import psycopg2\n",
    "\n",
    "subprocess.Popen('nvidia-smi', shell=True).wait()\n",
    "process = subprocess.Popen('docker container start spatialyze-gsstore', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bcaf7b9-8b3f-4f2f-ad00-08b197795820",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 1\n"
     ]
    }
   ],
   "source": [
    "hostname = socket.gethostname()\n",
    "test = hostname.split(\"-\")[-1]\n",
    "print(\"test\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df967c40-baae-4473-8ab4-0ddfd630eb59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chanwutk/spatialyze\n"
     ]
    }
   ],
   "source": [
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            # Jupyter notebook or qtconsole\n",
    "            return True\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            # Terminal running IPython\n",
    "            return False\n",
    "        else:\n",
    "            # Other type (?)\n",
    "            return False\n",
    "    except NameError:\n",
    "        # Probably standard Python interpreter\n",
    "        return False\n",
    "\n",
    "\n",
    "if is_notebook():\n",
    "    %cd ../..\n",
    "    from tqdm.notebook import tqdm\n",
    "    # from ..evaluation.nbutils.report_progress import report_progress\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    # from evaluation.ablation.nbutils.report_progress import report_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edb4d993-d0a4-49d5-8b4d-1b3a62f66da4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatialyze-gsstore\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddcd5926-911d-437d-b67f-6814d5eb7c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n",
      " > 0: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "from spatialyze.video_processor.camera_config import camera_config\n",
    "from spatialyze.video_processor.payload import Payload\n",
    "from spatialyze.video_processor.pipeline import Pipeline\n",
    "from spatialyze.video_processor.video import Video\n",
    "from spatialyze.video_processor.metadata_json_encoder import MetadataJSONEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "863b7bd6-7bc4-4658-bb06-043ba955aef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stages\n",
    "from spatialyze.video_processor.stages.in_view import InView\n",
    "\n",
    "from spatialyze.video_processor.stages.decode_frame.decode_frame import DecodeFrame as StageDecodeFrame\n",
    "from spatialyze.video_processor.stages.decode_frame.parallel_decode_frame import ParallelDecodeFrame\n",
    "\n",
    "from spatialyze.video_processor.stages.detection_2d.detection_2d import Detection2D\n",
    "from spatialyze.video_processor.stages.detection_2d.yolo_detection import YoloDetection\n",
    "from spatialyze.video_processor.stages.detection_2d.object_type_filter import ObjectTypeFilter\n",
    "from spatialyze.video_processor.stages.detection_2d.ground_truth import GroundTruthDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ee9880e-27d0-47f3-a3dd-36b70d199d8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spatialyze.video_processor.stages.detection_3d.from_detection_2d_and_road import FromDetection2DAndRoad as StageFromDetection2DAndRoad\n",
    "from spatialyze.video_processor.stages.detection_3d.from_detection_2d_and_depth import FromDetection2DAndDepth as StageFromDetection2DAndDepth\n",
    "\n",
    "from spatialyze.video_processor.stages.depth_estimation import DepthEstimation\n",
    "\n",
    "from spatialyze.video_processor.stages.detection_estimation import DetectionEstimation\n",
    "from spatialyze.video_processor.stages.detection_estimation.segment_mapping import RoadPolygonInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c4bddca-a1ae-4806-be85-8cf397d01ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spatialyze.video_processor.stages.tracking.strongsort import StrongSORT as StageStrongSORT\n",
    "from spatialyze.video_processor.stages.tracking_2d.strongsort import StrongSORT as StrongSORT2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6737b34b-d928-45aa-940e-b23a7a6e5eb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spatialyze.video_processor.stages.tracking_3d.from_tracking_2d_and_road import FromTracking2DAndRoad\n",
    "from spatialyze.video_processor.stages.tracking_3d.from_tracking_2d_and_depth import FromTracking2DAndDepth\n",
    "from spatialyze.video_processor.stages.tracking_3d.tracking_3d import Tracking3DResult, Tracking3D\n",
    "from spatialyze.video_processor.stages.tracking_3d.from_tracking_2d_and_detection_3d import FromTracking2DAndDetection3D as FromT2DAndD3D\n",
    "\n",
    "# from spatialyze.video_processor.stages.segment_trajectory import SegmentTrajectory\n",
    "# from spatialyze.video_processor.stages.segment_trajectory.construct_segment_trajectory import SegmentPoint\n",
    "# from spatialyze.video_processor.stages.segment_trajectory.from_tracking_3d import FromTracking3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9087777-3c98-414a-8f00-eda64e8f8ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream Processing\n",
    "from spatialyze.video_processor.stream.decode_frame import DecodeFrame\n",
    "from spatialyze.video_processor.stream.prune_frames import PruneFrames\n",
    "from spatialyze.video_processor.stream.road_visibility_pruner import RoadVisibilityPruner\n",
    "from spatialyze.video_processor.stream.mono_depth_estimator import MonoDepthEstimator\n",
    "from spatialyze.video_processor.stream.yolo import Yolo\n",
    "from spatialyze.video_processor.stream.object_type_pruner import ObjectTypePruner\n",
    "from spatialyze.video_processor.stream.from_detection_2d_and_road import FromDetection2DAndRoad\n",
    "from spatialyze.video_processor.stream.from_detection_2d_and_depth import FromDetection2DAndDepth\n",
    "from spatialyze.video_processor.stream.exit_frame_sampler import ExitFrameSampler\n",
    "from spatialyze.video_processor.stream.strongsort import StrongSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59907886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from spatialyze.video_processor.cache import disable_cache\n",
    "# disable_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e650e6ca-9d7c-41e9-98ee-f682b399040f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from spatialyze.video_processor.utils.process_pipeline import format_trajectory, insert_trajectory, get_tracks\n",
    "from spatialyze.video_processor.utils.prepare_trajectory import prepare_trajectory\n",
    "from spatialyze.video_processor.utils.insert_trajectory import insert_trajectory\n",
    "from spatialyze.video_processor.actions.tracking2d_overlay import tracking2d_overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "264c8190-89ee-472a-bd73-d553eb3e3278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spatialyze.utils.ingest_road import ingest_road\n",
    "from spatialyze.database import database, Database\n",
    "# from spatialyze.legacy.world import empty_world\n",
    "from spatialyze.utils import F\n",
    "from spatialyze.predicate import camera, objects, lit, FindAllTablesVisitor, normalize, MapTablesTransformer, GenSqlVisitor\n",
    "from spatialyze.data_types.camera import Camera as ACamera\n",
    "from spatialyze.data_types.camera_config import CameraConfig as ACameraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "355b8977",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "/home/chanwutk/data/processed\n"
     ]
    }
   ],
   "source": [
    "NUSCENES_PROCESSED_DATA = \"NUSCENES_PROCESSED_DATA\"\n",
    "print(NUSCENES_PROCESSED_DATA in os.environ)\n",
    "print(os.environ['NUSCENES_PROCESSED_DATA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00c1dd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.environ[NUSCENES_PROCESSED_DATA]\n",
    "# with open(os.path.join(DATA_DIR, \"videos\", \"frames.pkl\"), \"rb\") as f:\n",
    "#     videos = pickle.load(f)\n",
    "# with open(os.path.join(DATA_DIR, 'videos', 'videos.json'), 'r') as f:\n",
    "#     videos = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f6981ac-60b4-43f4-9c3b-32a4e84e4aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0523 0778 467\n"
     ]
    }
   ],
   "source": [
    "with open('./data/evaluation/video-samples/boston-seaport.txt', 'r') as f:\n",
    "    sampled_scenes = f.read().split('\\n')\n",
    "print(sampled_scenes[0], sampled_scenes[-1], len(sampled_scenes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcb3599c-3807-4044-9636-45b2d94fe7e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BENCHMARK_DIR = \"./outputs/run\"\n",
    "\n",
    "\n",
    "def bm_dir(*args: \"str\"):\n",
    "    return os.path.join(BENCHMARK_DIR, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad97a25a-0356-4d7e-9096-f26c00d2d9d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sql(predicate: \"PredicateNode\"):\n",
    "    tables, camera = FindAllTablesVisitor()(predicate)\n",
    "    tables = sorted(tables)\n",
    "    mapping = {t: i for i, t in enumerate(tables)}\n",
    "    predicate = normalize(predicate)\n",
    "    predicate = MapTablesTransformer(mapping)(predicate)\n",
    "\n",
    "    t_tables = ''\n",
    "    t_outputs = ''\n",
    "    for i in range(len(tables)):\n",
    "        t_tables += '\\n' \\\n",
    "            'JOIN Item_General_Trajectory ' \\\n",
    "            f'AS t{i} ' \\\n",
    "            f'ON Cameras.timestamp <@ t{i}.trajCentroids::period'\n",
    "        t_outputs += f', t{i}.itemId'\n",
    "\n",
    "    return f\"\"\"\n",
    "        SELECT Cameras.frameNum {t_outputs}\n",
    "        FROM Cameras{t_tables}\n",
    "        WHERE\n",
    "        {GenSqlVisitor()(predicate)}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d4149a3-43b5-4531-90dd-31dd795bdaa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slices = {\n",
    "    \"noopt\": (0, 1),\n",
    "    \"inview\": (1, 2),\n",
    "    \"objectfilter\": (2, 3),\n",
    "    \"geo\": (3, 4),\n",
    "    \"de\": (4, 5),\n",
    "    \"opt\": (5, 6),\n",
    "    # \"optde\": (6, 7),\n",
    "    'dev': (0, 2),\n",
    "    'freddie': (1, 2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2071a0c1-a0f2-4a2e-98a8-ea66ee3e2756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spatialyze.video_processor.stream.list_images import ListImages\n",
    "from spatialyze.video_processor.stream.load_images import LoadImages\n",
    "from spatialyze.video_processor.stream.detect_topdown_cars import DetectTopDownCars\n",
    "from spatialyze.video_processor.stream.from_topdown_detection_2d import FromTopDownDetection2D\n",
    "from spatialyze.video_processor.stream.sort import SORT\n",
    "from spatialyze.video_processor.stream.topdown_road_visibility_pruner import TopDownRoadVisibilityPruner\n",
    "\n",
    "\n",
    "# start_date = datetime.datetime(2018, 1, 1, 1, 1, 1, 1, tzinfo=datetime.timezone.utc)\n",
    "start_date = datetime.datetime(\n",
    "    year=2018,\n",
    "    month=8,\n",
    "    day=27,\n",
    "    hour=15,\n",
    "    minute=51,\n",
    "    second=32,\n",
    "    microsecond=0\n",
    ")\n",
    "\n",
    "\n",
    "class TopDownCameraConfig(NamedTuple):\n",
    "    tl: tuple[float, float]\n",
    "    tr: tuple[float, float]\n",
    "    br: tuple[float, float]\n",
    "    bl: tuple[float, float]\n",
    "    camera_id: str\n",
    "    frame_id: int\n",
    "    filename: str\n",
    "    camera_translation: tuple[float, float, float]\n",
    "    camera_rotation: tuple[float, float, float, float]\n",
    "    camera_intrinsic: tuple[\n",
    "        tuple[float, float, float],\n",
    "        tuple[float, float, float],\n",
    "        tuple[float, float, float]\n",
    "    ]\n",
    "    ego_translation: tuple[float, float, float]\n",
    "    ego_rotation: tuple[float, float, float, float]\n",
    "    timestamp: datetime.datetime\n",
    "    camera_heading: float\n",
    "    ego_heading: float\n",
    "\n",
    "\n",
    "def make_config(v, idx: int, file: str):\n",
    "    timestamp = start_date + datetime.timedelta(milliseconds=40 * idx)\n",
    "    translation = [\n",
    "        *np.array(v).mean(axis=0).tolist(),\n",
    "        0\n",
    "    ]\n",
    "    return TopDownCameraConfig(\n",
    "        *v,\n",
    "        'camera1',\n",
    "        idx,\n",
    "        file,\n",
    "        translation,\n",
    "        (1, 0, 0, 0),\n",
    "        [[190, 0, 800], [0, 190, 450], [0, 0, 1]],\n",
    "        translation,\n",
    "        (1, 0, 0, 0),\n",
    "        timestamp,\n",
    "        0,\n",
    "        0,\n",
    "    )\n",
    "\n",
    "\n",
    "def run_benchmark(pipeline, filename, predicates, run=0, ignore_error=False):\n",
    "    print(filename)\n",
    "    metadata_strongsort = {}\n",
    "    metadata_d2d = {}\n",
    "    failed_videos = []\n",
    "\n",
    "    all_metadata = {\n",
    "        'detection': metadata_d2d,\n",
    "        'sort': metadata_strongsort,\n",
    "    }\n",
    "    # print('# of total    videos:', len(videos))\n",
    "\n",
    "    # names = set(sampled_scenes[:1])\n",
    "    # names = set(sampled_scenes)\n",
    "    # filtered_videos = [\n",
    "    #     n for n in videos\n",
    "    #     if n[6:10] in names and 'FRONT' in n # and n.endswith('FRONT')\n",
    "    # ]\n",
    "    # N = len(filtered_videos)\n",
    "    # print('# of filtered videos:', N)\n",
    "\n",
    "    # # s_from, s_to = slices[test]\n",
    "    # s_from, s_to = (int(test), int(test) + 1)\n",
    "    # STEP = math.ceil(N / 10)\n",
    "    # print('test', test)\n",
    "    # print('from', s_from*STEP)\n",
    "    # print('to  ', s_to*STEP)\n",
    "    # filtered_videos = filtered_videos[s_from*STEP:min(s_to*STEP, N)]\n",
    "    # print('# of sliced   videos:', len(filtered_videos))\n",
    "    # ingest_road(database, './data/scenic/road-network/boston-seaport')\n",
    "\n",
    "    for pre in [*all_metadata.keys(), 'qresult', 'performance', 'failedvideos']:\n",
    "        p = os.path.join(BENCHMARK_DIR, f\"{pre}--{filename}_{run}\")\n",
    "        if os.path.exists(p):\n",
    "            shutil.rmtree(p)\n",
    "        os.makedirs(p)\n",
    "\n",
    "    def save_perf():\n",
    "        for n, message in failed_videos:\n",
    "            p = bm_dir(f'failedvideos--{filename}_{run}', f'{n}.txt')\n",
    "            with open(p, \"w\") as f:\n",
    "                f.write(message)\n",
    "\n",
    "    i = 0\n",
    "    name = 1\n",
    "    try:\n",
    "        start_input = time.time()\n",
    "        video_filename = 'video'\n",
    "        with open('../data/data/align-out.json', 'r') as f:\n",
    "            video = json.load(f)\n",
    "\n",
    "        video = [\n",
    "            None\n",
    "            if v is None else\n",
    "            make_config(v, idx, file)\n",
    "            for idx, (v, file) in enumerate(zip(video, sorted(os.listdir('../data/frames/main'))))\n",
    "        ]\n",
    "\n",
    "        frames = Video('../data/frames/main', video)\n",
    "        time_input = time.time() - start_input\n",
    "\n",
    "        start_process = time.time()\n",
    "        inview = TopDownRoadVisibilityPruner()\n",
    "        image_files = ListImages()\n",
    "        # image_files = PruneFrames(inview, image_files)\n",
    "        d2d = DetectTopDownCars(image_files)\n",
    "        d3d = FromTopDownDetection2D(d2d)\n",
    "        tracks = SORT(d3d)\n",
    "        output = tracks.execute(frames)\n",
    "        time_process = time.time() - start_process\n",
    "\n",
    "        times_rquery = []\n",
    "        predicate = predicates[0]\n",
    "        start_rquery = time.time()\n",
    "        database.reset(True)\n",
    "\n",
    "        # Ingest Trackings\n",
    "        for track in output:\n",
    "            obj_id = track[0].object_id\n",
    "            trajectory = prepare_trajectory(\n",
    "                name,\n",
    "                obj_id,\n",
    "                track,\n",
    "                frames.camera_configs\n",
    "            )\n",
    "            if trajectory:\n",
    "                insert_trajectory(database, *trajectory)\n",
    "\n",
    "        # Ingest Camera\n",
    "        accs: 'ACameraConfig' = []\n",
    "        camera_id = ''\n",
    "        for idx, cc in enumerate(frames.interpolated_frames):\n",
    "            if cc is None:\n",
    "                continue\n",
    "\n",
    "            camera_id = cc.camera_id\n",
    "            acc = ACameraConfig(\n",
    "                frame_id=cc.frame_id,\n",
    "                frame_num=idx,\n",
    "                filename=cc.filename,\n",
    "                camera_translation=cc.camera_translation,\n",
    "                camera_rotation=cc.camera_rotation,\n",
    "                camera_intrinsic=cc.camera_intrinsic,\n",
    "                ego_translation=cc.ego_translation,\n",
    "                ego_rotation=cc.ego_rotation,\n",
    "                timestamp=cc.timestamp,\n",
    "                cameraHeading=cc.camera_heading,\n",
    "                egoHeading=cc.ego_heading,\n",
    "            )\n",
    "            accs.append(acc)\n",
    "        camera = ACamera(accs, camera_id)\n",
    "        database.insert_camera(camera)\n",
    "\n",
    "        query = get_sql(predicate)\n",
    "        qresult = database.execute(query)\n",
    "\n",
    "        p = bm_dir(f\"qresult--{filename}_{run}\", f\"{name}-{i}.json\")\n",
    "        with open(p, 'w') as f:\n",
    "            json.dump(qresult, f, indent=1)\n",
    "        time_rquery = time.time() - start_rquery\n",
    "        times_rquery.append(time_rquery)\n",
    "        # runtime_query.append({'name': name, 'predicate': i, 'runtime': time_rquery})\n",
    "\n",
    "        # save video\n",
    "        start_video = time.time()\n",
    "        tracking2d_overlay(output, frames, '.')\n",
    "        time_video = time.time() - start_video\n",
    "        # runtime_video.append({'name': name, 'runtime': time_video})\n",
    "\n",
    "        perf = []\n",
    "#         for stage in pipeline.stages:\n",
    "#             benchmarks = [*filter(\n",
    "#                 lambda x: video['filename'] in x['name'],\n",
    "#                 stage.benchmark\n",
    "#             )]\n",
    "#             assert len(benchmarks) == 1\n",
    "#             perf.append({\n",
    "#                 'stage': stage.classname(),\n",
    "#                 'benchmark': benchmarks[0]\n",
    "#             })\n",
    "\n",
    "#             for bm in getattr(stage, '_benchmark', []):\n",
    "#                 if video['filename'] in bm['name']:\n",
    "#                     perf.append({\n",
    "#                         'stage': stage.classname(),\n",
    "#                         'addition': True,\n",
    "#                         'benchmark': bm,\n",
    "#                     })\n",
    "\n",
    "        perf.append({\n",
    "            'stage': 'ingest',\n",
    "            'benchmark': {\n",
    "                'name': name,\n",
    "                'runtime': time_input\n",
    "            }\n",
    "        })\n",
    "        perf.append({\n",
    "            'stage': 'process',\n",
    "            'benchmark': {\n",
    "                'name': name,\n",
    "                'runtime': time_process\n",
    "            }\n",
    "        })\n",
    "        perf.append({\n",
    "            'stage': 'save',\n",
    "            'benchmark': {\n",
    "                'name': name,\n",
    "                'runtime': time_video\n",
    "            }\n",
    "        })\n",
    "        for i, time_rquery in enumerate(times_rquery):\n",
    "            perf.append({\n",
    "                'stage': 'query',\n",
    "                'benchmark': {\n",
    "                    'name': name,\n",
    "                    'predicate': i,\n",
    "                    'runtime': time_rquery\n",
    "                }\n",
    "            })\n",
    "        p = bm_dir(f'performance--{filename}_{run}', f'{name}.json')\n",
    "        with open(p, \"w\") as f:\n",
    "            json.dump(perf, f, indent=1)\n",
    "    except Exception as e:\n",
    "        if ignore_error:\n",
    "            message = str(traceback.format_exc())\n",
    "            failed_videos.append((name, message))\n",
    "            print(video_filename)\n",
    "            print(e)\n",
    "            print(message)\n",
    "            print(\"------------------------------------------------------\")\n",
    "            print()\n",
    "            print()\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    save_perf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98283938-b68f-4925-a5ef-eee7c6c46c65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    groundtruth_detection=False,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True,\n",
    "    strongsort=False,\n",
    "    ss_update_when_skip=True,\n",
    "    ss_cache=True,\n",
    "):\n",
    "    pipeline = Pipeline()\n",
    "\n",
    "    # In-View Filter\n",
    "    if in_view:\n",
    "        # TODO: view angle and road type should depends on the predicate\n",
    "        pipeline.add_filter(InView(50, predicate=predicate))\n",
    "\n",
    "    # Decode\n",
    "    pipeline.add_filter(ParallelDecodeFrame())\n",
    "\n",
    "    # 2D Detection\n",
    "    if groundtruth_detection:\n",
    "        with open(os.path.join(DATA_DIR, 'annotation_partitioned.pkl'), 'rb') as f:\n",
    "            df_annotations = pickle.load(f)\n",
    "        pipeline.add_filter(GroundTruthDetection(df_annotations))\n",
    "    else:\n",
    "        pipeline.add_filter(YoloDetection())\n",
    "\n",
    "    # Object Filter\n",
    "    if object_filter:\n",
    "        pipeline.add_filter(ObjectTypeFilter(predicate=predicate))\n",
    "\n",
    "    # 3D Detection\n",
    "    if geo_depth:\n",
    "        pipeline.add_filter(StageFromDetection2DAndRoad())\n",
    "    else:\n",
    "        pipeline.add_filter(DepthEstimation())\n",
    "        pipeline.add_filter(StageFromDetection2DAndDepth())\n",
    "\n",
    "    # Detection Estimation\n",
    "    if detection_estimation:\n",
    "        pipeline.add_filter(DetectionEstimation())\n",
    "\n",
    "    # Tracking\n",
    "    pipeline.add_filter(StrongSORT2D(\n",
    "        # method='update-empty' if ss_update_when_skip else 'increment-ages',\n",
    "        method='update-empty',\n",
    "        cache=ss_cache,\n",
    "    ))\n",
    "\n",
    "    pipeline.add_filter(FromT2DAndD3D())\n",
    "    # if geo_depth:\n",
    "    #     pipeline.add_filter(FromTracking2DAndRoad())\n",
    "    # else:\n",
    "    #     pipeline.add_filter(FromTracking2DAndDepth())\n",
    "\n",
    "    # Segment Trajectory\n",
    "    # pipeline.add_filter(FromTracking3D())\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4adca3d-7963-4dc6-bde1-d0ce107ae959",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_noSSOpt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False,\n",
    "    ss_cache=False,\n",
    ")\n",
    "\n",
    "p_noOpt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_inview = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_objectFilter = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=True,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_geo = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_de = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=True\n",
    ")\n",
    "\n",
    "p_deIncr = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=True,\n",
    "    ss_update_when_skip=False,\n",
    ")\n",
    "\n",
    "p_opt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_optDe = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True\n",
    ")\n",
    "\n",
    "p_optIncr = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False,\n",
    "    ss_update_when_skip=False,\n",
    ")\n",
    "\n",
    "p_optDeIncr = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True,\n",
    "    ss_update_when_skip=False,\n",
    ")\n",
    "\n",
    "p_gtOpt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    groundtruth_detection=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_gtOptDe = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    groundtruth_detection=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True\n",
    ")\n",
    "\n",
    "pipelines = {\n",
    "    \"nossopt\": p_noSSOpt,\n",
    "    \"noopt\": p_noOpt,\n",
    "    \"inview\": p_inview,\n",
    "    \"objectfilter\": p_objectFilter,\n",
    "    \"geo\": p_geo,\n",
    "    \"de\": p_de,\n",
    "    # \"deincr\": p_deIncr,\n",
    "    \"opt\": p_opt,\n",
    "    # \"optincr\": p_optIncr,\n",
    "    \"optde\": p_optDe,\n",
    "    # \"optdeincr\": p_optDeIncr,\n",
    "\n",
    "    # \"gtopt\": p_gtOpt,\n",
    "    # \"gtoptde\": p_gtOptDe\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "653e586a-a98c-4c15-ac5a-17551b3155db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if test == 'dev':\n",
    "#     test = 'opt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48f7c558-dc6e-4b86-b447-a3ffac74c966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(__test):\n",
    "    obj1 = objects[0]\n",
    "    cam = camera\n",
    "    pred2 = (\n",
    "        ((obj1.type == 'car') | (obj1.type == 'truck')) &\n",
    "        F.contained(obj1.trans@cam.time, 'intersection')\n",
    "    )\n",
    "\n",
    "    p2 = pipelines[__test](pred2)\n",
    "\n",
    "    print('Pipeline P2:')\n",
    "    for s in p2.stages:\n",
    "        print(' -', s)\n",
    "    run_benchmark(p2, 'q2-' + __test, [pred2], run=1, ignore_error=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "811c4351-f2a7-478b-b264-69a3e8d75c69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 0 / 1 --- noopt -----------\n",
      "Pipeline P2:\n",
      " - DecodeFrame.ParallelDecodeFrame\n",
      " - Detection2D.YoloDetection\n",
      " - DepthEstimation\n",
      " - Detection3D.FromDetection2DAndDepth\n",
      " - Tracking2D.StrongSORT\n",
      " - Tracking3D.FromTracking2DAndDetection3D\n",
      "q2-noopt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "layer     filters    size              input                output\n",
      "    0 conv     32  3 x 3 / 1   960 x 512 x   3   ->   960 x 512 x  32  0.849 BFLOPs\n",
      "    1 conv     64  3 x 3 / 2   960 x 512 x  32   ->   480 x 256 x  64  4.530 BFLOPs\n",
      "    2 conv     32  1 x 1 / 1   480 x 256 x  64   ->   480 x 256 x  32  0.503 BFLOPs\n",
      "    3 conv     64  3 x 3 / 1   480 x 256 x  32   ->   480 x 256 x  64  4.530 BFLOPs\n",
      "    4 res    1                 480 x 256 x  64   ->   480 x 256 x  64\n",
      "    5 conv    128  3 x 3 / 2   480 x 256 x  64   ->   240 x 128 x 128  4.530 BFLOPs\n",
      "    6 conv     64  1 x 1 / 1   240 x 128 x 128   ->   240 x 128 x  64  0.503 BFLOPs\n",
      "    7 conv    128  3 x 3 / 1   240 x 128 x  64   ->   240 x 128 x 128  4.530 BFLOPs\n",
      "    8 res    5                 240 x 128 x 128   ->   240 x 128 x 128\n",
      "    9 conv     64  1 x 1 / 1   240 x 128 x 128   ->   240 x 128 x  64  0.503 BFLOPs\n",
      "   10 conv    128  3 x 3 / 1   240 x 128 x  64   ->   240 x 128 x 128  4.530 BFLOPs\n",
      "   11 res    8                 240 x 128 x 128   ->   240 x 128 x 128\n",
      "   12 conv    256  3 x 3 / 2   240 x 128 x 128   ->   120 x  64 x 256  4.530 BFLOPs\n",
      "   13 conv    128  1 x 1 / 1   120 x  64 x 256   ->   120 x  64 x 128  0.503 BFLOPs\n",
      "   14 conv    256  3 x 3 / 1   120 x  64 x 128   ->   120 x  64 x 256  4.530 BFLOPs\n",
      "   15 res   12                 120 x  64 x 256   ->   120 x  64 x 256\n",
      "   16 conv    128  1 x 1 / 1   120 x  64 x 256   ->   120 x  64 x 128  0.503 BFLOPs\n",
      "   17 conv    256  3 x 3 / 1   120 x  64 x 128   ->   120 x  64 x 256  4.530 BFLOPs\n",
      "   18 res   15                 120 x  64 x 256   ->   120 x  64 x 256\n",
      "   19 conv    128  1 x 1 / 1   120 x  64 x 256   ->   120 x  64 x 128  0.503 BFLOPs\n",
      "   20 conv    256  3 x 3 / 1   120 x  64 x 128   ->   120 x  64 x 256  4.530 BFLOPs\n",
      "   21 res   18                 120 x  64 x 256   ->   120 x  64 x 256\n",
      "   22 conv    128  1 x 1 / 1   120 x  64 x 256   ->   120 x  64 x 128  0.503 BFLOPs\n",
      "   23 conv    256  3 x 3 / 1   120 x  64 x 128   ->   120 x  64 x 256  4.530 BFLOPs\n",
      "   24 res   21                 120 x  64 x 256   ->   120 x  64 x 256\n",
      "   25 conv    128  1 x 1 / 1   120 x  64 x 256   ->   120 x  64 x 128  0.503 BFLOPs\n",
      "   26 conv    256  3 x 3 / 1   120 x  64 x 128   ->   120 x  64 x 256  4.530 BFLOPs\n",
      "   27 res   24                 120 x  64 x 256   ->   120 x  64 x 256\n",
      "   28 conv    128  1 x 1 / 1   120 x  64 x 256   ->   120 x  64 x 128  0.503 BFLOPs\n",
      "   29 conv    256  3 x 3 / 1   120 x  64 x 128   ->   120 x  64 x 256  4.530 BFLOPs\n",
      "   30 res   27                 120 x  64 x 256   ->   120 x  64 x 256\n",
      "   31 conv    128  1 x 1 / 1   120 x  64 x 256   ->   120 x  64 x 128  0.503 BFLOPs\n",
      "   32 conv    256  3 x 3 / 1   120 x  64 x 128   ->   120 x  64 x 256  4.530 BFLOPs\n",
      "   33 res   30                 120 x  64 x 256   ->   120 x  64 x 256\n",
      "   34 conv    128  1 x 1 / 1   120 x  64 x 256   ->   120 x  64 x 128  0.503 BFLOPs\n",
      "   35 conv    256  3 x 3 / 1   120 x  64 x 128   ->   120 x  64 x 256  4.530 BFLOPs\n",
      "   36 res   33                 120 x  64 x 256   ->   120 x  64 x 256\n",
      "   37 conv    512  3 x 3 / 2   120 x  64 x 256   ->    60 x  32 x 512  4.530 BFLOPs\n",
      "   38 conv    256  1 x 1 / 1    60 x  32 x 512   ->    60 x  32 x 256  0.503 BFLOPs\n",
      "   39 conv    512  3 x 3 / 1    60 x  32 x 256   ->    60 x  32 x 512  4.530 BFLOPs\n",
      "   40 res   37                  60 x  32 x 512   ->    60 x  32 x 512\n",
      "   41 conv    256  1 x 1 / 1    60 x  32 x 512   ->    60 x  32 x 256  0.503 BFLOPs\n",
      "   42 conv    512  3 x 3 / 1    60 x  32 x 256   ->    60 x  32 x 512  4.530 BFLOPs\n",
      "   43 res   40                  60 x  32 x 512   ->    60 x  32 x 512\n",
      "   44 conv    256  1 x 1 / 1    60 x  32 x 512   ->    60 x  32 x 256  0.503 BFLOPs\n",
      "   45 conv    512  3 x 3 / 1    60 x  32 x 256   ->    60 x  32 x 512  4.530 BFLOPs\n",
      "   46 res   43                  60 x  32 x 512   ->    60 x  32 x 512\n",
      "   47 conv    256  1 x 1 / 1    60 x  32 x 512   ->    60 x  32 x 256  0.503 BFLOPs\n",
      "   48 conv    512  3 x 3 / 1    60 x  32 x 256   ->    60 x  32 x 512  4.530 BFLOPs\n",
      "   49 res   46                  60 x  32 x 512   ->    60 x  32 x 512\n",
      "   50 conv    256  1 x 1 / 1    60 x  32 x 512   ->    60 x  32 x 256  0.503 BFLOPs\n",
      "   51 conv    512  3 x 3 / 1    60 x  32 x 256   ->    60 x  32 x 512  4.530 BFLOPs\n",
      "   52 res   49                  60 x  32 x 512   ->    60 x  32 x 512\n",
      "   53 conv    256  1 x 1 / 1    60 x  32 x 512   ->    60 x  32 x 256  0.503 BFLOPs\n",
      "   54 conv    512  3 x 3 / 1    60 x  32 x 256   ->    60 x  32 x 512  4.530 BFLOPs\n",
      "   55 res   52                  60 x  32 x 512   ->    60 x  32 x 512\n",
      "   56 conv    256  1 x 1 / 1    60 x  32 x 512   ->    60 x  32 x 256  0.503 BFLOPs\n",
      "   57 conv    512  3 x 3 / 1    60 x  32 x 256   ->    60 x  32 x 512  4.530 BFLOPs\n",
      "   58 res   55                  60 x  32 x 512   ->    60 x  32 x 512\n",
      "   59 conv    256  1 x 1 / 1    60 x  32 x 512   ->    60 x  32 x 256  0.503 BFLOPs\n",
      "   60 conv    512  3 x 3 / 1    60 x  32 x 256   ->    60 x  32 x 512  4.530 BFLOPs\n",
      "   61 res   58                  60 x  32 x 512   ->    60 x  32 x 512\n",
      "   62 conv   1024  3 x 3 / 2    60 x  32 x 512   ->    30 x  16 x1024  4.530 BFLOPs\n",
      "   63 conv    512  1 x 1 / 1    30 x  16 x1024   ->    30 x  16 x 512  0.503 BFLOPs\n",
      "   64 conv   1024  3 x 3 / 1    30 x  16 x 512   ->    30 x  16 x1024  4.530 BFLOPs\n",
      "   65 res   62                  30 x  16 x1024   ->    30 x  16 x1024\n",
      "   66 conv    512  1 x 1 / 1    30 x  16 x1024   ->    30 x  16 x 512  0.503 BFLOPs\n",
      "   67 conv   1024  3 x 3 / 1    30 x  16 x 512   ->    30 x  16 x1024  4.530 BFLOPs\n",
      "   68 res   65                  30 x  16 x1024   ->    30 x  16 x1024\n",
      "   69 conv    512  1 x 1 / 1    30 x  16 x1024   ->    30 x  16 x 512  0.503 BFLOPs\n",
      "   70 conv   1024  3 x 3 / 1    30 x  16 x 512   ->    30 x  16 x1024  4.530 BFLOPs\n",
      "   71 res   68                  30 x  16 x1024   ->    30 x  16 x1024\n",
      "   72 conv    512  1 x 1 / 1    30 x  16 x1024   ->    30 x  16 x 512  0.503 BFLOPs\n",
      "   73 conv   1024  3 x 3 / 1    30 x  16 x 512   ->    30 x  16 x1024  4.530 BFLOPs\n",
      "   74 res   71                  30 x  16 x1024   ->    30 x  16 x1024\n",
      "   75 conv    512  1 x 1 / 1    30 x  16 x1024   ->    30 x  16 x 512  0.503 BFLOPs\n",
      "   76 conv   1024  3 x 3 / 1    30 x  16 x 512   ->    30 x  16 x1024  4.530 BFLOPs\n",
      "   77 conv    512  1 x 1 / 1    30 x  16 x1024   ->    30 x  16 x 512  0.503 BFLOPs\n",
      "   78 conv   1024  3 x 3 / 1    30 x  16 x 512   ->    30 x  16 x1024  4.530 BFLOPs\n",
      "   79 conv    512  1 x 1 / 1    30 x  16 x1024   ->    30 x  16 x 512  0.503 BFLOPs\n",
      "   80 conv   1024  3 x 3 / 1    30 x  16 x 512   ->    30 x  16 x1024  4.530 BFLOPs\n",
      "   81 conv     18  1 x 1 / 1    30 x  16 x1024   ->    30 x  16 x  18  0.018 BFLOPs\n",
      "   82 yolo\n",
      "   83 route  79\n",
      "   84 conv    256  1 x 1 / 1    30 x  16 x 512   ->    30 x  16 x 256  0.126 BFLOPs\n",
      "   85 upsample            2x    30 x  16 x 256   ->    60 x  32 x 256\n",
      "   86 route  85 61\n",
      "   87 conv    256  1 x 1 / 1    60 x  32 x 768   ->    60 x  32 x 256  0.755 BFLOPs\n",
      "   88 conv    512  3 x 3 / 1    60 x  32 x 256   ->    60 x  32 x 512  4.530 BFLOPs\n",
      "   89 conv    256  1 x 1 / 1    60 x  32 x 512   ->    60 x  32 x 256  0.503 BFLOPs\n",
      "   90 conv    512  3 x 3 / 1    60 x  32 x 256   ->    60 x  32 x 512  4.530 BFLOPs\n",
      "   91 conv    256  1 x 1 / 1    60 x  32 x 512   ->    60 x  32 x 256  0.503 BFLOPs\n",
      "   92 conv    512  3 x 3 / 1    60 x  32 x 256   ->    60 x  32 x 512  4.530 BFLOPs\n",
      "   93 conv     18  1 x 1 / 1    60 x  32 x 512   ->    60 x  32 x  18  0.035 BFLOPs\n",
      "   94 yolo\n",
      "   95 route  91\n",
      "   96 conv    128  1 x 1 / 1    60 x  32 x 256   ->    60 x  32 x 128  0.126 BFLOPs\n",
      "   97 upsample            2x    60 x  32 x 128   ->   120 x  64 x 128\n",
      "   98 route  97 36\n",
      "   99 conv    128  1 x 1 / 1   120 x  64 x 384   ->   120 x  64 x 128  0.755 BFLOPs\n",
      "  100 conv    256  3 x 3 / 1   120 x  64 x 128   ->   120 x  64 x 256  4.530 BFLOPs\n",
      "  101 conv    128  1 x 1 / 1   120 x  64 x 256   ->   120 x  64 x 128  0.503 BFLOPs\n",
      "  102 conv    256  3 x 3 / 1   120 x  64 x 128   ->   120 x  64 x 256  4.530 BFLOPs\n",
      "  103 conv    128  1 x 1 / 1   120 x  64 x 256   ->   120 x  64 x 128  0.503 BFLOPs\n",
      "  104 conv    256  3 x 3 / 1   120 x  64 x 128   ->   120 x  64 x 256  4.530 BFLOPs\n",
      "  105 conv     18  1 x 1 / 1   120 x  64 x 256   ->   120 x  64 x  18  0.071 BFLOPs\n",
      "  106 yolo\n",
      "Loading weights from /home/chanwutk/spatialyze/data/skyquery/car-model/yolov3.best...Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e7b9b9b1f74504a62eefb82e61f3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17853 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29af196ea284ab68f82a9d8b0551a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17853 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tests = ['optde', 'de', 'noopt', 'inview', 'objectfilter', 'geo', 'opt']\n",
    "# tests = ['de', 'noopt', 'inview', 'objectfilter']\n",
    "tests = ['noopt']\n",
    "# random.shuffle(tests)\n",
    "\n",
    "for _test in tests:\n",
    "    assert isinstance(pipelines[_test](lit(True)), Pipeline)\n",
    "\n",
    "for idx, _test in enumerate(tests):\n",
    "    print(f'----------- {idx} / {len(tests)} --- {_test} -----------')\n",
    "    done = False\n",
    "    retry = 0\n",
    "    while not done and retry < 5:\n",
    "        # try:\n",
    "        run(_test)\n",
    "        done = True\n",
    "        # except Exception as e:\n",
    "        #     print(type(e))\n",
    "        #     print(e)\n",
    "        #     print('retrying...')\n",
    "        #     time.sleep(60)\n",
    "        #     retry += 1\n",
    "        #     with open(os.path.join(BENCHMARK_DIR, f'exception--bm{test}-t{_test}-r{retry}'), 'w') as f:\n",
    "        #         f.write(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "443364e8-c58b-4940-9fd4-539ee77d043c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c14e9fd-6083-4351-bceb-6b31b19a4e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if test == 'opt':\n",
    "#     run('optde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ce1a04b-e888-417c-967a-0399f1c8c75c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not is_notebook():\n",
    "    subprocess.Popen('sudo shutdown -h now', shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
