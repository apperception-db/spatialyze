{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from os import environ\n",
    "# environ[\"AP_PORT\"] = \"25432\" # str(input('port'))\n",
    "# README command uses port=25432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import datetime\n",
    "from pyquaternion import Quaternion\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def savenrow(nrow: int):\n",
    "    print(f'   ----------------------- nrow --------------', nrow)\n",
    "    with open('nrow.txt', 'w') as f:\n",
    "        f.write(str(nrow))\n",
    "\n",
    "def savert(t: float, text: str):\n",
    "    e = time.time() - t\n",
    "    print(f'   ----------------------- {text} --------------', e)\n",
    "    with open('benchmark.txt', 'r') as f:\n",
    "        bm = f.read()\n",
    "    with open('benchmark.txt', 'w') as f:\n",
    "        f.write(bm)\n",
    "        f.write('\\n')\n",
    "        f.write(text + ': ' + str(e))\n",
    "\n",
    "\n",
    "with open('benchmark.txt', 'w') as f:\n",
    "    f.write('')\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "from spatialyze.database import database\n",
    "from spatialyze.geospatial_video import GeospatialVideo\n",
    "from spatialyze.road_network import RoadNetwork\n",
    "from spatialyze.video_processor.camera_config import camera_config\n",
    "from spatialyze.video_processor.stages.tracking_3d.tracking_3d import Tracking3DResult\n",
    "from spatialyze.world import World, _execute\n",
    "from spatialyze.video_processor.cache import disable_cache\n",
    "from spatialyze.video_processor.metadata_json_encoder import MetadataJSONEncoder\n",
    "from spatialyze.utils import F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = '/home/chanwutk/viva-results'\n",
    "VIDEO_DIR = '/home/chanwutk/viva-data'\n",
    "# ROAD_DIR = '../../data/scenic/road-network/boston-seaport'\n",
    "\n",
    "VIDEO_NAME = 'output-small.mp4'\n",
    "\n",
    "disable_cache()\n",
    "savert(starttime, 'setup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = time.time()\n",
    "images = []\n",
    "idx = 0\n",
    "last = None\n",
    "frame_count = 0\n",
    "for i in tqdm(range(1, 960 + 1), total=960):\n",
    "    # print('video', i)\n",
    "    cap = cv2.VideoCapture(os.path.join(VIDEO_DIR, str(i) + '.mp4'))\n",
    "    # print(cap.get(cv2.CAP_PROP_FPS))\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            if idx % cap.get(cv2.CAP_PROP_FPS) == 0:\n",
    "                images.append(cv2.resize(frame, (360, 240)))\n",
    "                # writer.write(frame)\n",
    "                count += 1\n",
    "                # print('frame', frame_count)\n",
    "                frame_count += 1\n",
    "            last = frame\n",
    "        else:\n",
    "            break\n",
    "        idx += 1\n",
    "    # print('c=', count)\n",
    "    cap.release()\n",
    "images.append(cv2.resize(last, (360, 240)))\n",
    "cv2.destroyAllWindows()\n",
    "savert(starttime, 'resize-videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)\n",
    "_size = 0\n",
    "for x in images:\n",
    "    _size += x.size * x.itemsize\n",
    "_size / 1000 / 1000 / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = time.time()\n",
    "writer = cv2.VideoWriter(\n",
    "    os.path.join(VIDEO_DIR, VIDEO_NAME),\n",
    "    cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "    1,\n",
    "    (360, 240),\n",
    ")\n",
    "\n",
    "for img in images:\n",
    "    # print(img.shape)\n",
    "    writer.write(img)\n",
    "\n",
    "writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "savert(starttime, 'save-resized-videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# database = Database(\n",
    "#     psycopg2.connect(\n",
    "#         dbname=environ.get(\"AP_DB\", \"mobilitydb\"),\n",
    "#         user=environ.get(\"AP_USER\", \"docker\"),\n",
    "#         host=environ.get(\"AP_HOST\", \"localhost\"),\n",
    "#         port=environ.get(\"AP_PORT\", \"25432\"),\n",
    "#         password=environ.get(\"AP_PASSWORD\", \"docker\"),\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = time.time()\n",
    "world = World(database)\n",
    "# world.addGeogConstructs(RoadNetwork('Boston-Seaport', ROAD_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAMERA_INTRINSIC_FULL = np.array([\n",
    "    [1272,    0, 960],\n",
    "    [   0, 1272, 540],\n",
    "    [   0,    0,   1],\n",
    "])\n",
    "CAMERA_INTRINSIC = CAMERA_INTRINSIC_FULL * np.array([\n",
    "    360 / 1920,\n",
    "    240 / 1080,\n",
    "    1\n",
    "]).reshape((3, 1))\n",
    "CAMERA_TRANSLATION = np.array([0, 0, 5])\n",
    "CAMERA_ROTATION = Quaternion((0.430, -0.561, 0.561, -0.430))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videofile = os.path.join(VIDEO_DIR, VIDEO_NAME)\n",
    "\n",
    "start_date = datetime.datetime(\n",
    "    year=2018,\n",
    "    month=8,\n",
    "    day=27,\n",
    "    hour=15,\n",
    "    minute=51,\n",
    "    second=32,\n",
    "    microsecond=0\n",
    ")\n",
    "\n",
    "\n",
    "def config(idx: int):\n",
    "    timestamp = start_date + datetime.timedelta(seconds=idx)\n",
    "    return camera_config(\n",
    "        camera_id='camera-1',\n",
    "        camera_heading=90,\n",
    "        camera_intrinsic=CAMERA_INTRINSIC,\n",
    "        camera_translation=CAMERA_TRANSLATION,\n",
    "        ego_heading=0,\n",
    "        ego_rotation=Quaternion((1, 0, 0, 0)),\n",
    "        camera_rotation=CAMERA_ROTATION,\n",
    "        filename=videofile,\n",
    "        ego_translation=np.array([0, 0, 0]),\n",
    "        frame_id=frame,\n",
    "        frame_num=frame,\n",
    "        location=\"viva-data\",\n",
    "        timestamp=timestamp,\n",
    "        road_direction=0,\n",
    "    )\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(videofile)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "world.addVideo(GeospatialVideo(\n",
    "    videofile,\n",
    "    [*map(config, range(frame_count))],\n",
    "))\n",
    "savert(starttime, 'load-videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = time.time()\n",
    "o = world.object()\n",
    "p = world.object()\n",
    "c = world.camera()\n",
    "world.filter(\n",
    "    (o.type == 'car') & (p.type == 'person') &\n",
    "    # F.contained(o.trans@c.time, 'intersection') &\n",
    "    F.left_turn(o)\n",
    ")\n",
    "savert(starttime, 'define-query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "starttime = time.time()\n",
    "# result = world.getObjects()\n",
    "world.saveVideos(outputDir=OUTPUT_DIR, addBoundingBoxes=True)\n",
    "savert(starttime, 'process-and-annotate')\n",
    "# end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import NamedTuple\n",
    "\n",
    "import cv2\n",
    "\n",
    "from spatialyze.data_types.query_result import QueryResult\n",
    "from spatialyze.video_processor.stages.tracking_3d.tracking_3d import Metadatum as T3DMetadatum\n",
    "from spatialyze.utils.get_object_list import MovableObject, get_object_list\n",
    "\n",
    "TEXT_PADDING = 5\n",
    "\n",
    "def save_video_util(\n",
    "    objects: \"dict[str, list[QueryResult]]\",\n",
    "    trackings: \"dict[str, list[T3DMetadatum]]\",\n",
    "    outputDir: \"str\",\n",
    "    addBoundingBoxes: \"bool\" = False,\n",
    ") -> \"list[tuple[str, int]]\":\n",
    "    objList = get_object_list(objects=objects, trackings=trackings)\n",
    "    camera_to_video, video_to_camera = _get_video_names(objects=objects)\n",
    "    bboxes = _get_bboxes(objList=objList, cameraVideoNames=camera_to_video)\n",
    "\n",
    "    result: \"list[tuple[str, int]]\" = []\n",
    "\n",
    "    if not os.path.exists(outputDir):\n",
    "        os.makedirs(outputDir)\n",
    "\n",
    "    for videoname, frame_tracking in bboxes.items():\n",
    "        cameraId = video_to_camera[videoname]\n",
    "        output_file = os.path.join(outputDir, cameraId + \"-result.mp4\")\n",
    "\n",
    "        cap = cv2.VideoCapture(videoname)\n",
    "        assert cap.isOpened(), f\"Cannot read video file: {videoname}\"\n",
    "\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        vid_writer = cv2.VideoWriter(\n",
    "            output_file, cv2.VideoWriter_fourcc(*\"mp4v\"), 1, (width, height)\n",
    "        )\n",
    "\n",
    "        frame_cnt = 0\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if frame_cnt in frame_tracking:\n",
    "                if addBoundingBoxes:\n",
    "                    for bbox in frame_tracking.get(frame_cnt, []):\n",
    "                        object_id, object_type, bbox_left, bbox_top, bbox_w, bbox_h = bbox\n",
    "                        x1, y1 = bbox_left, bbox_top\n",
    "                        x2, y2 = bbox_left + bbox_w, bbox_top + bbox_h\n",
    "                        x1, y1, x2, y2 = map(int, (x1, y1, x2, y2))\n",
    "\n",
    "                        bboxColor = 255, 255, 0\n",
    "\n",
    "                        # Place Bounding Box\n",
    "                        frame = cv2.rectangle(frame, (x1, y1), (x2, y2), bboxColor, 2)\n",
    "\n",
    "                        # Place Label Background\n",
    "                        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                        fontScale = 1\n",
    "                        fontThickness = 2\n",
    "                        label = f\"{object_type}:{object_id}\"\n",
    "                        labelSize, _ = cv2.getTextSize(label, font, fontScale, fontThickness)\n",
    "                        labelW, labelH = labelSize\n",
    "\n",
    "                        frame = cv2.rectangle(\n",
    "                            frame,\n",
    "                            (x1, y1 - labelH - 2 * TEXT_PADDING),\n",
    "                            (x1 + labelW + 2 * TEXT_PADDING, y1),\n",
    "                            bboxColor,\n",
    "                            cv2.FILLED,\n",
    "                        )\n",
    "\n",
    "                        # Place Label\n",
    "                        frame = cv2.putText(\n",
    "                            frame,\n",
    "                            label,\n",
    "                            (x1 + TEXT_PADDING, y1 - TEXT_PADDING),\n",
    "                            font,\n",
    "                            fontScale,\n",
    "                            (255, 255, 255),\n",
    "                            fontThickness,\n",
    "                            cv2.LINE_AA,\n",
    "                        )\n",
    "                vid_writer.write(frame)\n",
    "                result.append((videoname, frame_cnt))\n",
    "\n",
    "            frame_cnt += 1\n",
    "\n",
    "        vid_writer.release()\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "class BboxWithIdAndType(NamedTuple):\n",
    "    id: \"int\"\n",
    "    type: \"str\"\n",
    "    left: \"float\"\n",
    "    top: \"float\"\n",
    "    width: \"float\"\n",
    "    height: \"float\"\n",
    "\n",
    "\n",
    "def _get_bboxes(objList: \"list[MovableObject]\", cameraVideoNames: \"dict[str, str]\"):\n",
    "    \"\"\"\n",
    "    Indexes objects based on frame ID\n",
    "    \"\"\"\n",
    "    result: \"dict[str, dict[int, list[BboxWithIdAndType]]]\" = {}\n",
    "    for obj in objList:\n",
    "        videoName = cameraVideoNames[obj.camera_id]\n",
    "        for frameId, bbox in zip(obj.frame_ids, obj.bboxes):\n",
    "            if videoName not in result:\n",
    "                result[videoName] = {}\n",
    "            if frameId not in result[videoName]:\n",
    "                result[videoName][frameId] = []\n",
    "            result[videoName][frameId].append(BboxWithIdAndType(obj.id, obj.type, *bbox))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def _get_video_names(objects: \"dict[str, list[QueryResult]]\"):\n",
    "    \"\"\"\n",
    "    Returns mappings from videoName to cameraId and vice versa\n",
    "    \"\"\"\n",
    "    camera_to_video: \"dict[str, str]\" = {}\n",
    "    video_to_camera: \"dict[str, str]\" = {}\n",
    "    for video, obj in filter(lambda x: len(x[1]) > 0, objects.items()):\n",
    "        _, cameraId, _, _ = obj[0]\n",
    "        camera_to_video[cameraId] = video\n",
    "        video_to_camera[video] = cameraId\n",
    "    return camera_to_video, video_to_camera\n",
    "\n",
    "\n",
    "save_video_util(world._objects, world._trackings, OUTPUT_DIR, addBoundingBoxes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"result\", format(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = time.time()\n",
    "result = world.getObjects()\n",
    "savert(starttime, 'process-and-objects')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world.saveVideos(outputDir=OUTPUT_DIR, addBoundingBoxes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "84811f0b18467531d9159c52389f859386c3fe2775a4d2964ee51061827c5c88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
