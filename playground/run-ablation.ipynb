{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "569e4726-2856-4e5f-a220-e3bef1c110e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec  3 00:54:53 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA TITAN Xp                 On | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 27%   47C    P2               60W / 250W|   1916MiB / 12288MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA TITAN Xp                 On | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 23%   27C    P8                9W / 250W|      1MiB / 12288MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA TITAN Xp                 On | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 23%   21C    P8                8W / 250W|      1MiB / 12288MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA TITAN Xp                 On | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 23%   28C    P8                9W / 250W|      1MiB / 12288MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA TITAN Xp                 On | 00000000:88:00.0 Off |                  N/A |\n",
      "| 23%   22C    P8                8W / 250W|      1MiB / 12288MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA TITAN Xp                 On | 00000000:89:00.0 Off |                  N/A |\n",
      "| 23%   24C    P8                8W / 250W|      1MiB / 12288MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import traceback\n",
    "import shutil\n",
    "import socket\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "from os import environ\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import psycopg2\n",
    "\n",
    "subprocess.Popen('nvidia-smi', shell=True).wait()\n",
    "process = subprocess.Popen('docker container start mobilitydb', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bcaf7b9-8b3f-4f2f-ad00-08b197795820",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test freddie\n"
     ]
    }
   ],
   "source": [
    "hostname = socket.gethostname()\n",
    "test = hostname.split(\"-\")[-1]\n",
    "print(\"test\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df967c40-baae-4473-8ab4-0ddfd630eb59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/chanwutk/projects/spatialyze-viva\n"
     ]
    }
   ],
   "source": [
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            # Jupyter notebook or qtconsole\n",
    "            return True\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            # Terminal running IPython\n",
    "            return False\n",
    "        else:\n",
    "            # Other type (?)\n",
    "            return False\n",
    "    except NameError:\n",
    "        # Probably standard Python interpreter\n",
    "        return False\n",
    "\n",
    "\n",
    "if is_notebook():\n",
    "    %cd ..\n",
    "    from tqdm.notebook import tqdm\n",
    "    from nbutils.report_progress import report_progress\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    from playground.nbutils.report_progress import report_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edb4d993-d0a4-49d5-8b4d-1b3a62f66da4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error response from daemon: No such container: mobilitydb\n",
      "Error: failed to start containers: mobilitydb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddcd5926-911d-437d-b67f-6814d5eb7c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n",
      " > 0: NVIDIA TITAN Xp\n",
      "   1: NVIDIA TITAN Xp\n",
      "   2: NVIDIA TITAN Xp\n",
      "   3: NVIDIA TITAN Xp\n",
      "   4: NVIDIA TITAN Xp\n"
     ]
    }
   ],
   "source": [
    "from spatialyze.video_processor.camera_config import camera_config\n",
    "from spatialyze.video_processor.payload import Payload\n",
    "from spatialyze.video_processor.pipeline import Pipeline\n",
    "from spatialyze.video_processor.video import Video\n",
    "from spatialyze.video_processor.metadata_json_encoder import MetadataJSONEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "863b7bd6-7bc4-4658-bb06-043ba955aef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stages\n",
    "from spatialyze.video_processor.stages.in_view import InView\n",
    "\n",
    "from spatialyze.video_processor.stages.decode_frame.decode_frame import DecodeFrame\n",
    "from spatialyze.video_processor.stages.decode_frame.parallel_decode_frame import ParallelDecodeFrame\n",
    "\n",
    "from spatialyze.video_processor.stages.detection_2d.detection_2d import Detection2D\n",
    "from spatialyze.video_processor.stages.detection_2d.yolo_detection import YoloDetection\n",
    "from spatialyze.video_processor.stages.detection_2d.object_type_filter import ObjectTypeFilter\n",
    "from spatialyze.video_processor.stages.detection_2d.ground_truth import GroundTruthDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ee9880e-27d0-47f3-a3dd-36b70d199d8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spatialyze.video_processor.stages.detection_3d.from_detection_2d_and_road import FromDetection2DAndRoad\n",
    "from spatialyze.video_processor.stages.detection_3d.from_detection_2d_and_depth import FromDetection2DAndDepth\n",
    "\n",
    "from spatialyze.video_processor.stages.depth_estimation import DepthEstimation\n",
    "\n",
    "from spatialyze.video_processor.stages.detection_estimation import DetectionEstimation\n",
    "from spatialyze.video_processor.stages.detection_estimation.segment_mapping import RoadPolygonInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1649aa-f852-442a-916f-486d6b3193df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c4bddca-a1ae-4806-be85-8cf397d01ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/modules/yolo_deepsort/deep_sort/deep/reid/torchreid/metrics/rank.py:11: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from spatialyze.video_processor.stages.tracking.strongsort import StrongSORT\n",
    "# from spatialyze.video_processor.stages.tracking_2d.strongsort import StrongSORT as StrongSORT2D\n",
    "from spatialyze.video_processor.stages.tracking_2d.deepsort import DeepSORT as DeepSORT2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcd14f1-4485-43db-9723-a18e568da240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6737b34b-d928-45aa-940e-b23a7a6e5eb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spatialyze.video_processor.stages.tracking_3d.from_tracking_2d_and_road import FromTracking2DAndRoad\n",
    "from spatialyze.video_processor.stages.tracking_3d.from_tracking_2d_and_depth import FromTracking2DAndDepth\n",
    "from spatialyze.video_processor.stages.tracking_3d.tracking_3d import Tracking3DResult, Tracking3D\n",
    "from spatialyze.video_processor.stages.tracking_3d.from_tracking_2d_and_detection_3d import FromTracking2DAndDetection3D as FromT2DAndD3D\n",
    "\n",
    "from spatialyze.video_processor.stages.segment_trajectory import SegmentTrajectory\n",
    "# from spatialyze.video_processor.stages.segment_trajectory.construct_segment_trajectory import SegmentPoint\n",
    "from spatialyze.video_processor.stages.segment_trajectory.from_tracking_3d import FromTracking3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59907886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spatialyze.video_processor.cache import disable_cache\n",
    "disable_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e650e6ca-9d7c-41e9-98ee-f682b399040f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from spatialyze.video_processor.utils.process_pipeline import format_trajectory, insert_trajectory, get_tracks\n",
    "# from spatialyze.video_processor.actions.tracking2d_overlay import tracking2d_overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "264c8190-89ee-472a-bd73-d553eb3e3278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spatialyze.utils.ingest_road import ingest_road\n",
    "from spatialyze.database import database, Database\n",
    "# from spatialyze.legacy.world import empty_world\n",
    "from spatialyze.utils import F\n",
    "from spatialyze.predicate import camera, objects, lit, FindAllTablesVisitor, normalize, MapTablesTransformer, GenSqlVisitor\n",
    "from spatialyze.data_types.camera import Camera as ACamera\n",
    "from spatialyze.data_types.camera_config import CameraConfig as ACameraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "355b8977",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "/data/apperception-data/processed/nuscenes/full-dataset-v1.0/Trainval\n"
     ]
    }
   ],
   "source": [
    "NUSCENES_PROCESSED_DATA = \"NUSCENES_PROCESSED_DATA\"\n",
    "print(NUSCENES_PROCESSED_DATA in os.environ)\n",
    "print(os.environ['NUSCENES_PROCESSED_DATA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00c1dd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.environ[NUSCENES_PROCESSED_DATA]\n",
    "# with open(os.path.join(DATA_DIR, \"videos\", \"frames.pkl\"), \"rb\") as f:\n",
    "#     videos = pickle.load(f)\n",
    "with open(os.path.join(DATA_DIR, 'videos', 'videos.json'), 'r') as f:\n",
    "    videos = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f6981ac-60b4-43f4-9c3b-32a4e84e4aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0523 0778 467\n"
     ]
    }
   ],
   "source": [
    "with open('./data/evaluation/video-samples/boston-seaport.txt', 'r') as f:\n",
    "    sampled_scenes = f.read().split('\\n')\n",
    "print(sampled_scenes[0], sampled_scenes[-1], len(sampled_scenes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcb3599c-3807-4044-9636-45b2d94fe7e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BENCHMARK_DIR = \"./outputs/run\"\n",
    "\n",
    "\n",
    "def bm_dir(*args: \"str\"):\n",
    "    return os.path.join(BENCHMARK_DIR, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad97a25a-0356-4d7e-9096-f26c00d2d9d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sql(predicate: \"PredicateNode\"):\n",
    "    tables, camera = FindAllTablesVisitor()(predicate)\n",
    "    tables = sorted(tables)\n",
    "    mapping = {t: i for i, t in enumerate(tables)}\n",
    "    predicate = normalize(predicate)\n",
    "    predicate = MapTablesTransformer(mapping)(predicate)\n",
    "\n",
    "    t_tables = ''\n",
    "    t_outputs = ''\n",
    "    for i in range(len(tables)):\n",
    "        t_tables += '\\n' \\\n",
    "            'JOIN Item_General_Trajectory ' \\\n",
    "            f'AS t{i} ' \\\n",
    "            f'ON Cameras.timestamp <@ t{i}.trajCentroids::period'\n",
    "        t_outputs += f', t{i}.itemId'\n",
    "\n",
    "    return f\"\"\"\n",
    "        SELECT Cameras.frameNum {t_outputs}\n",
    "        FROM Cameras{t_tables}\n",
    "        WHERE\n",
    "        {GenSqlVisitor()(predicate)}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d4149a3-43b5-4531-90dd-31dd795bdaa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slices = {\n",
    "    \"noopt\": (0, 1),\n",
    "    \"inview\": (1, 2),\n",
    "    \"objectfilter\": (2, 3),\n",
    "    \"geo\": (3, 4),\n",
    "    \"de\": (4, 5),\n",
    "    \"opt\": (5, 6),\n",
    "    # \"optde\": (6, 7),\n",
    "    'dev': (0, 2),\n",
    "    'freddie': (1, 2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "275836d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_benchmark(pipeline, filename, predicates, run=0, ignore_error=False):\n",
    "    print(filename)\n",
    "    metadata_strongsort = {}\n",
    "    metadata_d2d = {}\n",
    "    failed_videos = []\n",
    "\n",
    "    all_metadata = {\n",
    "        'detection': metadata_d2d,\n",
    "        'sort': metadata_strongsort,\n",
    "    }\n",
    "    print('# of total    videos:', len(videos))\n",
    "\n",
    "    names = set(sampled_scenes[:80])\n",
    "    # names = set(sampled_scenes)\n",
    "    filtered_videos = [\n",
    "        n for n in videos\n",
    "        if n[6:10] in names and 'FRONT' in n # and n.endswith('FRONT')\n",
    "    ]\n",
    "    N = len(filtered_videos)\n",
    "    print('# of filtered videos:', N)\n",
    "\n",
    "    # # s_from, s_to = slices[test]\n",
    "    # s_from, s_to = (int(test), int(test) + 1)\n",
    "    # STEP = math.ceil(N / 10)\n",
    "    # print('test', test)\n",
    "    # print('from', s_from*STEP)\n",
    "    # print('to  ', s_to*STEP)\n",
    "    # filtered_videos = filtered_videos[s_from*STEP:min(s_to*STEP, N)]\n",
    "    print('# of sliced   videos:', len(filtered_videos))\n",
    "    # ingest_road(database, './data/scenic/road-network/boston-seaport')\n",
    "\n",
    "    for pre in [*all_metadata.keys(), 'qresult', 'performance', 'failedvideos']:\n",
    "        p = os.path.join(BENCHMARK_DIR, f\"{pre}--{filename}_{run}\")\n",
    "        if os.path.exists(p):\n",
    "            shutil.rmtree(p)\n",
    "        os.makedirs(p)\n",
    "\n",
    "    def save_perf():\n",
    "        for n, message in failed_videos:\n",
    "            p = bm_dir(f'failedvideos--{filename}_{run}', f'{n}.txt')\n",
    "            with open(p, \"w\") as f:\n",
    "                f.write(message)\n",
    "\n",
    "    for i, name in tqdm(enumerate(filtered_videos), total=len(filtered_videos)):\n",
    "        try:\n",
    "            start_input = time.time()\n",
    "            with open(os.path.join(DATA_DIR, 'videos', 'boston-seaport-' + name + '.pkl'), 'rb') as f:\n",
    "                video = pickle.load(f)\n",
    "            video_filename = video['filename']\n",
    "\n",
    "            frames = Video(\n",
    "                os.path.join(DATA_DIR, \"videos\", video[\"filename\"]),\n",
    "                [camera_config(*f, 0) for f in video[\"frames\"]],\n",
    "            )\n",
    "            time_input = time.time() - start_input\n",
    "\n",
    "            output = pipeline.run(Payload(frames))\n",
    "\n",
    "            metadata_strongsort[name] = output[StrongSORT2D]\n",
    "            metadata_d2d[name] = output[Detection2D]\n",
    "\n",
    "            for pre, metadata in all_metadata.items():\n",
    "                p = bm_dir(f\"{pre}--{filename}_{run}\", f\"{name}.json\")\n",
    "                with open(p, \"w\") as f:\n",
    "                    json.dump(metadata[name], f, cls=MetadataJSONEncoder,\n",
    "                              indent=1)\n",
    "\n",
    "            times_rquery = []\n",
    "            for i, predicate in enumerate(predicates):\n",
    "                start_rquery = time.time()\n",
    "                database.reset(True)\n",
    "\n",
    "                # Ingest Trackings\n",
    "                ego_meta = frames.interpolated_frames\n",
    "                sortmeta = Tracking3D.get(output)\n",
    "                assert sortmeta is not None\n",
    "                segment_trajectories = FromTracking3D.get(output)\n",
    "                # tracks = get_tracks(sortmeta, ego_meta, segment_trajectories)\n",
    "                # for obj_id, track in tracks.items():\n",
    "                #     trajectory = format_trajectory(name, obj_id, track)\n",
    "                #     if trajectory:\n",
    "                #         insert_trajectory(database, *trajectory[0])\n",
    "\n",
    "                # Ingest Camera\n",
    "                accs: 'ACameraConfig' = []\n",
    "                for idx, cc in enumerate(frames.interpolated_frames):\n",
    "                    acc = ACameraConfig(\n",
    "                        frame_id=cc.frame_id,\n",
    "                        frame_num=idx,\n",
    "                        filename=cc.filename,\n",
    "                        camera_translation=cc.camera_translation,\n",
    "                        camera_rotation=cc.camera_rotation,\n",
    "                        camera_intrinsic=cc.camera_intrinsic,\n",
    "                        ego_translation=cc.ego_translation,\n",
    "                        ego_rotation=cc.ego_rotation,\n",
    "                        timestamp=cc.timestamp,\n",
    "                        cameraHeading=cc.camera_heading,\n",
    "                        egoHeading=cc.ego_heading,\n",
    "                    )\n",
    "                    accs.append(acc)\n",
    "                camera = ACamera(accs, cc.camera_id)\n",
    "                database.insert_cam(camera)\n",
    "\n",
    "                query = get_sql(predicate)\n",
    "                qresult = database.execute(query)\n",
    "\n",
    "                p = bm_dir(f\"qresult--{filename}_{run}\", f\"{name}-{i}.json\")\n",
    "                with open(p, 'w') as f:\n",
    "                    json.dump(qresult, f, indent=1)\n",
    "                time_rquery = time.time() - start_rquery\n",
    "                times_rquery.append(time_rquery)\n",
    "                # runtime_query.append({'name': name, 'predicate': i, 'runtime': time_rquery})\n",
    "\n",
    "            # save video\n",
    "            start_video = time.time()\n",
    "            tracking2d_overlay(output, './tmp.mp4')\n",
    "            time_video = time.time() - start_video\n",
    "            # runtime_video.append({'name': name, 'runtime': time_video})\n",
    "\n",
    "            perf = []\n",
    "            for stage in pipeline.stages:\n",
    "                benchmarks = [*filter(\n",
    "                    lambda x: video['filename'] in x['name'],\n",
    "                    stage.benchmark\n",
    "                )]\n",
    "                assert len(benchmarks) == 1\n",
    "                perf.append({\n",
    "                    'stage': stage.classname(),\n",
    "                    'benchmark': benchmarks[0]\n",
    "                })\n",
    "\n",
    "                for bm in getattr(stage, '_benchmark', []):\n",
    "                    if video['filename'] in bm['name']:\n",
    "                        perf.append({\n",
    "                            'stage': stage.classname(),\n",
    "                            'addition': True,\n",
    "                            'benchmark': bm,\n",
    "                        })\n",
    "\n",
    "            perf.append({\n",
    "                'stage': 'ingest',\n",
    "                'benchmark': {\n",
    "                    'name': name,\n",
    "                    'runtime': time_input\n",
    "                }\n",
    "            })\n",
    "            perf.append({\n",
    "                'stage': 'save',\n",
    "                'benchmark': {\n",
    "                    'name': name,\n",
    "                    'runtime': time_video\n",
    "                }\n",
    "            })\n",
    "            for i, time_rquery in enumerate(times_rquery):\n",
    "                perf.append({\n",
    "                    'stage': 'query',\n",
    "                    'benchmark': {\n",
    "                        'name': name,\n",
    "                        'predicate': i,\n",
    "                        'runtime': time_rquery\n",
    "                    }\n",
    "                })\n",
    "            p = bm_dir(f'performance--{filename}_{run}', f'{name}.json')\n",
    "            with open(p, \"w\") as f:\n",
    "                json.dump(perf, f, indent=1)\n",
    "        except Exception as e:\n",
    "            if ignore_error:\n",
    "                message = str(traceback.format_exc())\n",
    "                failed_videos.append((name, message))\n",
    "                print(video_filename)\n",
    "                print(e)\n",
    "                print(message)\n",
    "                print(\"------------------------------------------------------------------------------------\")\n",
    "                print()\n",
    "                print()\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "        if len(metadata_d2d) % 10 == 0:\n",
    "            save_perf()\n",
    "    save_perf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98283938-b68f-4925-a5ef-eee7c6c46c65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    groundtruth_detection=False,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True,\n",
    "    strongsort=False,\n",
    "    ss_update_when_skip=True,\n",
    "    ss_cache=True,\n",
    "):\n",
    "    pipeline = Pipeline()\n",
    "\n",
    "    # In-View Filter\n",
    "    if in_view:\n",
    "        # TODO: view angle and road type should depends on the predicate\n",
    "        pipeline.add_filter(InView(50, predicate=predicate))\n",
    "\n",
    "    # Decode\n",
    "    pipeline.add_filter(ParallelDecodeFrame())\n",
    "\n",
    "    # 2D Detection\n",
    "    if groundtruth_detection:\n",
    "        with open(os.path.join(DATA_DIR, 'annotation_partitioned.pkl'), 'rb') as f:\n",
    "            df_annotations = pickle.load(f)\n",
    "        pipeline.add_filter(GroundTruthDetection(df_annotations))\n",
    "    else:\n",
    "        pipeline.add_filter(YoloDetection())\n",
    "\n",
    "    # Object Filter\n",
    "    if object_filter:\n",
    "        pipeline.add_filter(ObjectTypeFilter(predicate=predicate))\n",
    "\n",
    "    # 3D Detection\n",
    "    if geo_depth:\n",
    "        pipeline.add_filter(FromDetection2DAndRoad())\n",
    "    else:\n",
    "        pipeline.add_filter(DepthEstimation())\n",
    "        pipeline.add_filter(FromDetection2DAndDepth())\n",
    "\n",
    "    # Detection Estimation\n",
    "    if detection_estimation:\n",
    "        pipeline.add_filter(DetectionEstimation())\n",
    "\n",
    "    # Tracking\n",
    "    pipeline.add_filter(DeepSORT2D())\n",
    "    # pipeline.add_filter(StrongSORT2D(\n",
    "    #     # method='update-empty' if ss_update_when_skip else 'increment-ages',\n",
    "    #     method='update-empty',\n",
    "    #     cache=ss_cache,\n",
    "    # ))\n",
    "\n",
    "    pipeline.add_filter(FromT2DAndD3D())\n",
    "    # if geo_depth:\n",
    "    #     pipeline.add_filter(FromTracking2DAndRoad())\n",
    "    # else:\n",
    "    #     pipeline.add_filter(FromTracking2DAndDepth())\n",
    "\n",
    "    # Segment Trajectory\n",
    "    # pipeline.add_filter(FromTracking3D())\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4adca3d-7963-4dc6-bde1-d0ce107ae959",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_noSSOpt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False,\n",
    "    ss_cache=False,\n",
    ")\n",
    "\n",
    "p_noOpt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_inview = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_objectFilter = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=True,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_geo = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_de = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=True\n",
    ")\n",
    "\n",
    "p_deIncr = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=False,\n",
    "    object_filter=False,\n",
    "    geo_depth=False,\n",
    "    detection_estimation=True,\n",
    "    ss_update_when_skip=False,\n",
    ")\n",
    "\n",
    "p_opt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_optDe = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True\n",
    ")\n",
    "\n",
    "p_optIncr = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False,\n",
    "    ss_update_when_skip=False,\n",
    ")\n",
    "\n",
    "p_optDeIncr = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True,\n",
    "    ss_update_when_skip=False,\n",
    ")\n",
    "\n",
    "p_gtOpt = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    groundtruth_detection=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=False\n",
    ")\n",
    "\n",
    "p_gtOptDe = lambda predicate: create_pipeline(\n",
    "    predicate,\n",
    "    in_view=True,\n",
    "    object_filter=True,\n",
    "    groundtruth_detection=True,\n",
    "    geo_depth=True,\n",
    "    detection_estimation=True\n",
    ")\n",
    "\n",
    "pipelines = {\n",
    "    \"nossopt\": p_noSSOpt,\n",
    "    \"noopt\": p_noOpt,\n",
    "    \"inview\": p_inview,\n",
    "    \"objectfilter\": p_objectFilter,\n",
    "    \"geo\": p_geo,\n",
    "    \"de\": p_de,\n",
    "    # \"deincr\": p_deIncr,\n",
    "    \"opt\": p_opt,\n",
    "    # \"optincr\": p_optIncr,\n",
    "    \"optde\": p_optDe,\n",
    "    # \"optdeincr\": p_optDeIncr,\n",
    "\n",
    "    # \"gtopt\": p_gtOpt,\n",
    "    # \"gtoptde\": p_gtOptDe\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "653e586a-a98c-4c15-ac5a-17551b3155db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if test == 'dev':\n",
    "#     test = 'opt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48f7c558-dc6e-4b86-b447-a3ffac74c966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(__test):\n",
    "    o = objects[0]\n",
    "    c = camera\n",
    "    pred1 = (\n",
    "        (o.type == 'person') &\n",
    "        # F.contained(c.ego, 'intersection') &\n",
    "        F.contained(o.trans@c.time, 'intersection') &\n",
    "        F.angle_excluding(F.facing_relative(o.traj@c.time, c.cam), lit(-70), lit(70)) &\n",
    "        # F.angle_between(F.facing_relative(c.cam, F.road_direction(c.ego)), lit(-15), lit(15)) &\n",
    "        (F.distance(c.cam, o.traj@c.time) < lit(50)) # &\n",
    "        # (F.view_angle(o.trans@c.time, c.camAbs) < lit(35))\n",
    "    )\n",
    "    pred1_notrack = (\n",
    "        F.contained(o.trans@c.time, 'intersection') &\n",
    "        (F.distance(c.cam, o.traj@c.time) < lit(50)) &\n",
    "        (o.type == 'person')\n",
    "    )\n",
    "\n",
    "    obj1 = objects[0]\n",
    "    obj2 = objects[1]\n",
    "    cam = camera\n",
    "    pred2 = (\n",
    "        (obj1.id != obj2.id) &\n",
    "        ((obj1.type == 'car') | (obj1.type == 'truck')) &\n",
    "        ((obj2.type == 'car') | (obj2.type == 'truck')) &\n",
    "        F.angle_between(F.facing_relative(cam.cam, F.road_direction(cam.cam)), -15, 15) &\n",
    "        (F.distance(cam.cam, obj1.trans@cam.time) < 50) &\n",
    "\n",
    "        # (F.view_angle(obj1.trans@cam.time, cam.ego) < 70 / 2.0) &\n",
    "        (F.distance(cam.cam, obj2.trans@cam.time) < 50) &\n",
    "        # (F.view_angle(obj2.trans@cam.time, cam.ego) < 70 / 2.0) &\n",
    "        F.contains_all('intersection', [obj1.trans, obj2.trans]@cam.time) &\n",
    "        # F.angle_between(F.facing_relative(obj1.trans@cam.time, cam.cam), 40, 135) &\n",
    "        # F.angle_between(F.facing_relative(obj2.trans@cam.time, cam.cam), -135, -50)\n",
    "        F.angle_between(F.facing_relative(obj1.trans@cam.time, obj2.trans@cam.time), -180, -90)\n",
    "        # (F.min_distance(cam.ego, 'intersection') < 10) &\n",
    "        # F.angle_between(F.facing_relative(obj1.trans@cam.time, obj2.trans@cam.time), 100, -100)\n",
    "    )\n",
    "    pred2_notrack = (\n",
    "        (F.distance(cam.cam, obj1.trans@cam.time) < 50) &\n",
    "        (F.distance(cam.cam, obj2.trans@cam.time) < 50) &\n",
    "        F.contains_all('intersection', [obj1.trans, obj2.trans]@cam.time) &\n",
    "        (obj1.id != obj2.id) &\n",
    "        ((obj1.type == 'car') | (obj1.type == 'truck')) &\n",
    "        ((obj2.type == 'car') | (obj2.type == 'truck'))\n",
    "    )\n",
    "\n",
    "    obj1 = objects[0]\n",
    "    cam = camera\n",
    "    pred3 = (\n",
    "        ((obj1.type == 'car') | (obj1.type == 'truck')) &\n",
    "        # (F.view_angle(obj1.trans@cam.time, cam.ego) < 70 / 2) &\n",
    "        F.angle_between(F.facing_relative(cam.cam, F.road_direction(cam.ego, cam.ego)), 135, 225) &\n",
    "        F.contained(cam.cam, F.road_segment('lane')) &\n",
    "        F.contained(obj1.trans@cam.time, F.road_segment('lane')) &\n",
    "        F.angle_between(F.facing_relative(obj1.trans@cam.time, F.road_direction(obj1.traj@cam.time, cam.ego)), -15, 15) &\n",
    "        # F.angle_between(F.facing_relative(obj1.trans@cam.time, cam.ego), 135, 225) &\n",
    "        (F.distance(cam.cam, obj1.trans@cam.time) < 10)\n",
    "    )\n",
    "    pred3_notrack = (\n",
    "        # F.contained(cam.cam, F.road_segment('lane')) &\n",
    "        F.contained(obj1.trans@cam.time, F.road_segment('lane')) &\n",
    "        (F.distance(cam.cam, obj1.trans@cam.time) < 10) &\n",
    "        ((obj1.type == 'car') | (obj1.type == 'truck'))\n",
    "    )\n",
    "\n",
    "    cam = camera\n",
    "    car1 = objects[0]\n",
    "    opposite_car_1 = objects[1]\n",
    "    opposite_car_2 = objects[2]\n",
    "\n",
    "    pred4 = (\n",
    "        ((car1.type == 'car') | (car1.type == 'truck')) &\n",
    "        ((opposite_car_2.type == 'car') | (opposite_car_2.type == 'truck')) &\n",
    "        ((opposite_car_1.type == 'car') | (opposite_car_1.type == 'truck')) &\n",
    "        (opposite_car_1.id != opposite_car_2.id) &\n",
    "        (car1.id != opposite_car_2.id) &\n",
    "        (car1.id != opposite_car_1.id) &\n",
    "\n",
    "        F.contained(cam.cam, F.road_segment('lane')) &\n",
    "        F.contained(car1.trans@cam.time, F.road_segment('lane')) &\n",
    "        F.contained(opposite_car_1.trans@cam.time, F.road_segment('lane')) &\n",
    "        F.contained(opposite_car_2.trans@cam.time, F.road_segment('lane')) &\n",
    "        F.angle_between(F.facing_relative(cam.cam, F.road_direction(cam.cam, cam.cam)), -15, 15) &\n",
    "        # (F.view_angle(car1.traj@cam.time, cam.ego) < 70 / 2) &\n",
    "        (F.distance(cam.cam, car1.traj@cam.time) < 40) &\n",
    "        F.angle_between(F.facing_relative(car1.traj@cam.time, cam.ego), -15, 15) &\n",
    "        # F.angle_between(F.facing_relative(car1.traj@cam.time, F.road_direction(car1.traj@cam.time, cam.ego)), -15, 15) &\n",
    "        F.ahead(car1.traj@cam.time, cam.cam) &\n",
    "        # (F.convert_camera(opposite_car.traj@cam.time, cam.ego) > [-10, 0]) &\n",
    "        # (F.convert_camera(opposite_car.traj@cam.time, cam.ego) < [-1, 50]) &\n",
    "        F.angle_between(F.facing_relative(opposite_car_1.traj@cam.time, cam.ego), 135, 225) &\n",
    "        # (F.distance(opposite_car@cam.time, car2@cam.time) < 40)# &\n",
    "        F.angle_between(F.facing_relative(opposite_car_2.traj@cam.time, opposite_car_1.traj@cam.time), -15, 15) &\n",
    "        F.angle_between(F.facing_relative(opposite_car_2.traj@cam.time, F.road_direction(opposite_car_2.traj@cam.time, cam.ego)), -15, 15) &\n",
    "        F.ahead(opposite_car_2.traj@cam.time, opposite_car_1.traj@cam.time)\n",
    "    )\n",
    "    pred4_notrack = (\n",
    "        # F.contained(cam.cam,                       F.road_segment('lane')) &\n",
    "        F.contained(car1.trans@cam.time,           F.road_segment('lane')) &\n",
    "        F.contained(opposite_car_1.trans@cam.time, F.road_segment('lane')) &\n",
    "        F.contained(opposite_car_2.trans@cam.time, F.road_segment('lane')) &\n",
    "        ((car1.type == 'car') | (car1.type == 'truck')) &\n",
    "        ((opposite_car_2.type == 'car') | (opposite_car_2.type == 'truck')) &\n",
    "        ((opposite_car_1.type == 'car') | (opposite_car_1.type == 'truck')) &\n",
    "        (opposite_car_1.id != opposite_car_2.id) &\n",
    "        (car1.id != opposite_car_2.id) &\n",
    "        (car1.id != opposite_car_1.id)\n",
    "    )\n",
    "\n",
    "    p1 = pipelines[__test](pred1)\n",
    "    p2 = pipelines[__test](pred2)\n",
    "    p34 = pipelines[__test](pred3)\n",
    "\n",
    "    print('Pipeline P2:')\n",
    "    for s in p2.stages:\n",
    "        print(' -', s)\n",
    "    run_benchmark(p2, 'q2-' + __test, [pred2, pred2_notrack], run=1, ignore_error=True)\n",
    "\n",
    "    print('Pipeline P3,P4:')\n",
    "    for s in p34.stages:\n",
    "        print(' -', s)\n",
    "    run_benchmark(p34, 'q34-' + __test, [pred3, pred4, pred3_notrack, pred4_notrack], run=1, ignore_error=True)\n",
    "\n",
    "    if __test != 'optde' and __test != 'de':\n",
    "        print('Pipeline P1:')\n",
    "        for s in p1.stages:\n",
    "            print(' -', s)\n",
    "        run_benchmark(p1, 'q1-' + __test, [pred1, pred1_notrack], run=1, ignore_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "811c4351-f2a7-478b-b264-69a3e8d75c69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chanwutk/.local/share/mambaforge/envs/spatialyze/lib/python3.10/site-packages/torch/hub.py:267: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /data/chanwutk/projects/spatialyze-viva/weights/master.zip\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['Pillow>=10.0.1'] not found, attempting AutoUpdate...\n",
      "Collecting Pillow>=10.0.1\n",
      "  Obtaining dependency information for Pillow>=10.0.1 from https://files.pythonhosted.org/packages/95/7b/71e2665760b5c33af00fa9bb6d6bca068b51bf021a4ceaeee03e18689f51/Pillow-10.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
      "Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Pillow\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 10.0.0\n",
      "    Uninstalling Pillow-10.0.0:\n",
      "      Successfully uninstalled Pillow-10.0.0\n",
      "Successfully installed Pillow-10.1.0\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 2.6s, installed 1 package: ['Pillow>=10.0.1']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['Pillow>=10.0.1'] not found, attempting AutoUpdate...\n",
      "Requirement already satisfied: Pillow>=10.0.1 in /data/chanwutk/.local/share/mambaforge/envs/spatialyze/lib/python3.10/site-packages (10.1.0)\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 1.8s, installed 1 package: ['Pillow>=10.0.1']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['Pillow>=10.0.1'] not found, attempting AutoUpdate...\n",
      "Requirement already satisfied: Pillow>=10.0.1 in /data/chanwutk/.local/share/mambaforge/envs/spatialyze/lib/python3.10/site-packages (10.1.0)\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 1.7s, installed 1 package: ['Pillow>=10.0.1']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['Pillow>=10.0.1'] not found, attempting AutoUpdate...\n",
      "Requirement already satisfied: Pillow>=10.0.1 in /data/chanwutk/.local/share/mambaforge/envs/spatialyze/lib/python3.10/site-packages (10.1.0)\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 1.7s, installed 1 package: ['Pillow>=10.0.1']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['Pillow>=10.0.1'] not found, attempting AutoUpdate...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 0 / 4 --- de -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow>=10.0.1 in /data/chanwutk/.local/share/mambaforge/envs/spatialyze/lib/python3.10/site-packages (10.1.0)\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 1.7s, installed 1 package: ['Pillow>=10.0.1']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['Pillow>=10.0.1'] not found, attempting AutoUpdate...\n",
      "Requirement already satisfied: Pillow>=10.0.1 in /data/chanwutk/.local/share/mambaforge/envs/spatialyze/lib/python3.10/site-packages (10.1.0)\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 1.7s, installed 1 package: ['Pillow>=10.0.1']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['Pillow>=10.0.1'] not found, attempting AutoUpdate...\n",
      "Requirement already satisfied: Pillow>=10.0.1 in /data/chanwutk/.local/share/mambaforge/envs/spatialyze/lib/python3.10/site-packages (10.1.0)\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 1.7s, installed 1 package: ['Pillow>=10.0.1']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline P2:\n",
      " - DecodeFrame.ParallelDecodeFrame\n",
      " - Detection2D.YoloDetection\n",
      " - DepthEstimation\n",
      " - Detection3D.FromDetection2DAndDepth\n",
      " - DetectionEstimation\n",
      " - Tracking2D.DeepSORT\n",
      " - Tracking3D.FromTracking2DAndDetection3D\n",
      "q2-de\n",
      "# of total    videos: 5100\n",
      "# of filtered videos: 240\n",
      "# of sliced   videos: 240\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab7b1c84aba435e93d77e6cfa4eb495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boston-seaport-scene-0068-CAM_FRONT.mp4\n",
      "column segmentpolygon.__roadtype__intersection__ does not exist\n",
      "LINE 15:         AND (SegmentPolygon.__RoadType__intersection__\n",
      "                      ^\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_20118/138723079.py\", line 57, in run_benchmark\n",
      "    output = pipeline.run(Payload(frames))\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/pipeline.py\", line 25, in run\n",
      "    payload = payload.filter(stage)\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/payload.py\", line 36, in filter\n",
      "    keep, metadata = filter.run(self)\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/stages/stage.py\", line 55, in run\n",
      "    out = self._run(payload)\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/stages/detection_estimation/__init__.py\", line 89, in _run\n",
      "    all_detection_info, times = construct_estimated_all_detection_info(\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/stages/detection_estimation/__init__.py\", line 252, in construct_estimated_all_detection_info\n",
      "    all_detection_info, times = construct_all_detection_info(\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/stages/detection_estimation/detection_estimation.py\", line 268, in construct_all_detection_info\n",
      "    detections_polygon_mapping, times = get_detection_polygon_mapping(all_detections, ego_config)\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/stages/detection_estimation/segment_mapping.py\", line 191, in get_detection_polygon_mapping\n",
      "    results = map_detections_to_segments(detections, ego_config)\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/stages/detection_estimation/segment_mapping.py\", line 158, in map_detections_to_segments\n",
      "    result = database.execute(out)\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/database.py\", line 201, in execute\n",
      "    results, cursor = self.execute_and_cursor(query, vars)\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/database.py\", line 196, in execute_and_cursor\n",
      "    raise error\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/database.py\", line 186, in execute_and_cursor\n",
      "    cursor.execute(query, vars)\n",
      "psycopg2.errors.UndefinedColumn: column segmentpolygon.__roadtype__intersection__ does not exist\n",
      "LINE 15:         AND (SegmentPolygon.__RoadType__intersection__\n",
      "                      ^\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "boston-seaport-scene-0068-CAM_FRONT_RIGHT.mp4\n",
      "column segmentpolygon.__roadtype__intersection__ does not exist\n",
      "LINE 15:         AND (SegmentPolygon.__RoadType__intersection__\n",
      "                      ^\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_20118/138723079.py\", line 57, in run_benchmark\n",
      "    output = pipeline.run(Payload(frames))\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/pipeline.py\", line 25, in run\n",
      "    payload = payload.filter(stage)\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/payload.py\", line 36, in filter\n",
      "    keep, metadata = filter.run(self)\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/stages/stage.py\", line 55, in run\n",
      "    out = self._run(payload)\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/stages/detection_estimation/__init__.py\", line 89, in _run\n",
      "    all_detection_info, times = construct_estimated_all_detection_info(\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/stages/detection_estimation/__init__.py\", line 252, in construct_estimated_all_detection_info\n",
      "    all_detection_info, times = construct_all_detection_info(\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/stages/detection_estimation/detection_estimation.py\", line 268, in construct_all_detection_info\n",
      "    detections_polygon_mapping, times = get_detection_polygon_mapping(all_detections, ego_config)\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/stages/detection_estimation/segment_mapping.py\", line 191, in get_detection_polygon_mapping\n",
      "    results = map_detections_to_segments(detections, ego_config)\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/stages/detection_estimation/segment_mapping.py\", line 158, in map_detections_to_segments\n",
      "    result = database.execute(out)\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/database.py\", line 201, in execute\n",
      "    results, cursor = self.execute_and_cursor(query, vars)\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/database.py\", line 196, in execute_and_cursor\n",
      "    raise error\n",
      "  File \"/data/chanwutk/projects/spatialyze-viva/spatialyze/database.py\", line 186, in execute_and_cursor\n",
      "    cursor.execute(query, vars)\n",
      "psycopg2.errors.UndefinedColumn: column segmentpolygon.__roadtype__intersection__ does not exist\n",
      "LINE 15:         AND (SegmentPolygon.__RoadType__intersection__\n",
      "                      ^\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done \u001b[38;5;129;01mand\u001b[39;00m retry \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m5\u001b[39m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m         \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m         done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[26], line 118\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(__test)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m p2\u001b[38;5;241m.\u001b[39mstages:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m -\u001b[39m\u001b[38;5;124m'\u001b[39m, s)\n\u001b[0;32m--> 118\u001b[0m \u001b[43mrun_benchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mq2-\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m__test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpred2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred2_notrack\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPipeline P3,P4:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m p34\u001b[38;5;241m.\u001b[39mstages:\n",
      "Cell \u001b[0;32mIn[22], line 57\u001b[0m, in \u001b[0;36mrun_benchmark\u001b[0;34m(pipeline, filename, predicates, run, ignore_error)\u001b[0m\n\u001b[1;32m     51\u001b[0m frames \u001b[38;5;241m=\u001b[39m Video(\n\u001b[1;32m     52\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideos\u001b[39m\u001b[38;5;124m\"\u001b[39m, video[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     53\u001b[0m     [camera_config(\u001b[38;5;241m*\u001b[39mf, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m video[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     55\u001b[0m time_input \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_input\n\u001b[0;32m---> 57\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPayload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m metadata_strongsort[name] \u001b[38;5;241m=\u001b[39m output[StrongSORT2D]\n\u001b[1;32m     60\u001b[0m metadata_d2d[name] \u001b[38;5;241m=\u001b[39m output[Detection2D]\n",
      "File \u001b[0;32m/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/pipeline.py:25\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, payload: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPayload\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPayload\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages:\n\u001b[0;32m---> 25\u001b[0m         payload \u001b[38;5;241m=\u001b[39m \u001b[43mpayload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m payload\n",
      "File \u001b[0;32m/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/payload.py:36\u001b[0m, in \u001b[0;36mPayload.filter\u001b[0;34m(self, filter)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mfilter\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStage\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# print(\"Stage: \", filter.classname())\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     keep, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         keep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep\n",
      "File \u001b[0;32m/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/stages/stage.py:55\u001b[0m, in \u001b[0;36mStage.run\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m     53\u001b[0m keep_before \u001b[38;5;241m=\u001b[39m payload\u001b[38;5;241m.\u001b[39mkeep\n\u001b[1;32m     54\u001b[0m s \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 55\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m e \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     57\u001b[0m keep_after \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/stages/depth_estimation.py:37\u001b[0m, in \u001b[0;36mDepthEstimation._run\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m         images\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 37\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[43mmd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassname(): metadata}\n",
      "File \u001b[0;32m/data/chanwutk/projects/spatialyze-viva/spatialyze/video_processor/stages/depth_estimation.py:131\u001b[0m, in \u001b[0;36mmonodepth.eval_all\u001b[0;34m(self, input_images)\u001b[0m\n\u001b[1;32m    126\u001b[0m         _, depth \u001b[38;5;241m=\u001b[39m disp_to_depth(disp, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m    127\u001b[0m         depth_resized \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39minterpolate(\n\u001b[1;32m    128\u001b[0m             depth, (original_height, original_width), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    129\u001b[0m         )\n\u001b[0;32m--> 131\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdepth_resized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5.4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tests = ['optde', 'de', 'noopt', 'inview', 'objectfilter', 'geo', 'opt']\n",
    "tests = ['de', 'noopt', 'inview', 'objectfilter']\n",
    "# random.shuffle(tests)\n",
    "\n",
    "for _test in tests:\n",
    "    assert isinstance(pipelines[_test](lit(True)), Pipeline)\n",
    "\n",
    "for idx, _test in enumerate(tests):\n",
    "    print(f'----------- {idx} / {len(tests)} --- {_test} -----------')\n",
    "    done = False\n",
    "    retry = 0\n",
    "    while not done and retry < 5:\n",
    "        try:\n",
    "            run(_test)\n",
    "            done = True\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('retrying...')\n",
    "            time.sleep(60)\n",
    "            retry += 1\n",
    "            with open(os.path.join(BENCHMARK_DIR, f'exception--bm{test}-t{_test}-r{retry}'), 'w') as f:\n",
    "                f.write(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443364e8-c58b-4940-9fd4-539ee77d043c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c14e9fd-6083-4351-bceb-6b31b19a4e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if test == 'opt':\n",
    "#     run('optde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce1a04b-e888-417c-967a-0399f1c8c75c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not is_notebook():\n",
    "    subprocess.Popen('sudo shutdown -h now', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ad6fa9-3d74-4dc1-989d-08dfda7f3489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
